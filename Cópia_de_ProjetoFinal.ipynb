{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f2UU0ScA8MdC",
        "HVPLyuXVTDbl",
        "83WDAkTgUsrH",
        "H1EPnWlH5F9h",
        "_rX06kOH_BZ6",
        "kiAV6ARx_BZ8",
        "2kLVliE_dOPt",
        "zQEvxmKpdeEr",
        "6ZngFfDcd_Ta",
        "di5Tr_QIGi1O",
        "pxoigMBmCZuk",
        "Rk4K6B2ysXjx",
        "29Co4_ls3KTo",
        "PUYSZJsk3KTq"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luanwma/IA_Projeto_Final/blob/main/C%C3%B3pia_de_ProjetoFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Luan William Marques Alvares\n",
        "## Mateus Luz Francischini Bonardi\n",
        "## Rafael Duarte Daltio"
      ],
      "metadata": {
        "id": "ckSwT8ArvhzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento e pré-processamento dos dados"
      ],
      "metadata": {
        "id": "f2UU0ScA8MdC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHJgWdAZu4Qx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics  as sts\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdLCgbECHPde",
        "outputId": "8354acd0-c627-4f6a-fc51-1c9bcad54f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('drive/MyDrive/Colab Notebooks/projetoFinal/Titanic-Dataset.csv')\n"
      ],
      "metadata": {
        "id": "QHDrDbZrwfKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "kKiJ4YYOwt60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128f629f-fe2c-4435-b796-340abd9a4af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "vf84NDEkz6jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d85ed41-afa2-4f8e-f7dd-dfa36030c7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(columns=['PassengerId','Name','Ticket'], axis=1)"
      ],
      "metadata": {
        "id": "kcY8X-aB4ob1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Age'].fillna(df['Age'].mean(), inplace=True)"
      ],
      "metadata": {
        "id": "UVfIs3G5H_JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "CSSmxkVuILph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['Sex'] = le.fit_transform(df['Sex'])"
      ],
      "metadata": {
        "id": "bnWzou9m0fgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.drop('Cabin', axis=1)\n",
        "df2 = pd.get_dummies(data = df2, columns=['Embarked'])\n",
        "df2 = pd.get_dummies(data=df2, columns=['Pclass'])\n",
        "df2\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "d2vr6x_Hha_j",
        "outputId": "7fec3e87-b403-4a94-ab5f-cc4ac58be7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Survived  Sex        Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n",
              "0           0    1  22.000000      1      0   7.2500           0           0   \n",
              "1           1    0  38.000000      1      0  71.2833           1           0   \n",
              "2           1    0  26.000000      0      0   7.9250           0           0   \n",
              "3           1    0  35.000000      1      0  53.1000           0           0   \n",
              "4           0    1  35.000000      0      0   8.0500           0           0   \n",
              "..        ...  ...        ...    ...    ...      ...         ...         ...   \n",
              "886         0    1  27.000000      0      0  13.0000           0           0   \n",
              "887         1    0  19.000000      0      0  30.0000           0           0   \n",
              "888         0    0  29.699118      1      2  23.4500           0           0   \n",
              "889         1    1  26.000000      0      0  30.0000           1           0   \n",
              "890         0    1  32.000000      0      0   7.7500           0           1   \n",
              "\n",
              "     Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
              "0             1         0         0         1  \n",
              "1             0         1         0         0  \n",
              "2             1         0         0         1  \n",
              "3             1         1         0         0  \n",
              "4             1         0         0         1  \n",
              "..          ...       ...       ...       ...  \n",
              "886           1         0         1         0  \n",
              "887           1         1         0         0  \n",
              "888           1         0         0         1  \n",
              "889           0         1         0         0  \n",
              "890           0         0         0         1  \n",
              "\n",
              "[891 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0c257bd-74b8-4ca2-a778-0195336b36ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0c257bd-74b8-4ca2-a778-0195336b36ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0c257bd-74b8-4ca2-a778-0195336b36ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0c257bd-74b8-4ca2-a778-0195336b36ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(data=df, columns=['Cabin'])\n",
        "df = pd.get_dummies(data=df, columns=['Embarked'])\n",
        "df = pd.get_dummies(data=df, columns=['Pclass'])\n",
        "df"
      ],
      "metadata": {
        "id": "qlbwAnrbIvtM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "55d95510-553f-420a-e6fa-6341562d6311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Survived  Sex        Age  SibSp  Parch     Fare  Cabin_A10  Cabin_A14  \\\n",
              "0           0    1  22.000000      1      0   7.2500          0          0   \n",
              "1           1    0  38.000000      1      0  71.2833          0          0   \n",
              "2           1    0  26.000000      0      0   7.9250          0          0   \n",
              "3           1    0  35.000000      1      0  53.1000          0          0   \n",
              "4           0    1  35.000000      0      0   8.0500          0          0   \n",
              "..        ...  ...        ...    ...    ...      ...        ...        ...   \n",
              "886         0    1  27.000000      0      0  13.0000          0          0   \n",
              "887         1    0  19.000000      0      0  30.0000          0          0   \n",
              "888         0    0  29.699118      1      2  23.4500          0          0   \n",
              "889         1    1  26.000000      0      0  30.0000          0          0   \n",
              "890         0    1  32.000000      0      0   7.7500          0          0   \n",
              "\n",
              "     Cabin_A16  Cabin_A19  ...  Cabin_F38  Cabin_F4  Cabin_G6  Cabin_T  \\\n",
              "0            0          0  ...          0         0         0        0   \n",
              "1            0          0  ...          0         0         0        0   \n",
              "2            0          0  ...          0         0         0        0   \n",
              "3            0          0  ...          0         0         0        0   \n",
              "4            0          0  ...          0         0         0        0   \n",
              "..         ...        ...  ...        ...       ...       ...      ...   \n",
              "886          0          0  ...          0         0         0        0   \n",
              "887          0          0  ...          0         0         0        0   \n",
              "888          0          0  ...          0         0         0        0   \n",
              "889          0          0  ...          0         0         0        0   \n",
              "890          0          0  ...          0         0         0        0   \n",
              "\n",
              "     Embarked_C  Embarked_Q  Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
              "0             0           0           1         0         0         1  \n",
              "1             1           0           0         1         0         0  \n",
              "2             0           0           1         0         0         1  \n",
              "3             0           0           1         1         0         0  \n",
              "4             0           0           1         0         0         1  \n",
              "..          ...         ...         ...       ...       ...       ...  \n",
              "886           0           0           1         0         1         0  \n",
              "887           0           0           1         1         0         0  \n",
              "888           0           0           1         0         0         1  \n",
              "889           1           0           0         1         0         0  \n",
              "890           0           1           0         0         0         1  \n",
              "\n",
              "[891 rows x 159 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05b7f12a-485c-4944-8505-7763199e36da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin_A10</th>\n",
              "      <th>Cabin_A14</th>\n",
              "      <th>Cabin_A16</th>\n",
              "      <th>Cabin_A19</th>\n",
              "      <th>...</th>\n",
              "      <th>Cabin_F38</th>\n",
              "      <th>Cabin_F4</th>\n",
              "      <th>Cabin_G6</th>\n",
              "      <th>Cabin_T</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 159 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05b7f12a-485c-4944-8505-7763199e36da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05b7f12a-485c-4944-8505-7763199e36da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05b7f12a-485c-4944-8505-7763199e36da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMALIZACAO"
      ],
      "metadata": {
        "id": "BIW2NNqN_qOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "std=StandardScaler()\n",
        "columns = ['Age','Fare']\n",
        "scaled = std.fit_transform(df[['Age','Fare']])\n",
        "scaled = pd.DataFrame(scaled,columns=columns)\n",
        "df=df.drop(columns=columns,axis=1)\n",
        "df2=df2.drop(columns=columns,axis=1)"
      ],
      "metadata": {
        "id": "JcKQJLox-JWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.merge(scaled, left_index=True, right_index=True, how = \"right\")\n",
        "df2=df2.merge(scaled, left_index=True, right_index=True, how = \"right\")\n",
        "df2"
      ],
      "metadata": {
        "id": "a2_kfgV6AxIj",
        "outputId": "0df0ad3f-ed9e-49c9-ddb9-124e422606db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Survived  Sex  SibSp  Parch  Embarked_C  Embarked_Q  Embarked_S  \\\n",
              "0           0    1      1      0           0           0           1   \n",
              "1           1    0      1      0           1           0           0   \n",
              "2           1    0      0      0           0           0           1   \n",
              "3           1    0      1      0           0           0           1   \n",
              "4           0    1      0      0           0           0           1   \n",
              "..        ...  ...    ...    ...         ...         ...         ...   \n",
              "886         0    1      0      0           0           0           1   \n",
              "887         1    0      0      0           0           0           1   \n",
              "888         0    0      1      2           0           0           1   \n",
              "889         1    1      0      0           1           0           0   \n",
              "890         0    1      0      0           0           1           0   \n",
              "\n",
              "     Pclass_1  Pclass_2  Pclass_3       Age      Fare  \n",
              "0           0         0         1 -0.592481 -0.502445  \n",
              "1           1         0         0  0.638789  0.786845  \n",
              "2           0         0         1 -0.284663 -0.488854  \n",
              "3           1         0         0  0.407926  0.420730  \n",
              "4           0         0         1  0.407926 -0.486337  \n",
              "..        ...       ...       ...       ...       ...  \n",
              "886         0         1         0 -0.207709 -0.386671  \n",
              "887         1         0         0 -0.823344 -0.044381  \n",
              "888         0         0         1  0.000000 -0.176263  \n",
              "889         1         0         0 -0.284663 -0.044381  \n",
              "890         0         0         1  0.177063 -0.492378  \n",
              "\n",
              "[891 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93267ccc-eb84-4093-990a-3dbbd4950ea3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.592481</td>\n",
              "      <td>-0.502445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.638789</td>\n",
              "      <td>0.786845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.284663</td>\n",
              "      <td>-0.488854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.407926</td>\n",
              "      <td>0.420730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.407926</td>\n",
              "      <td>-0.486337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.207709</td>\n",
              "      <td>-0.386671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.823344</td>\n",
              "      <td>-0.044381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.176263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.284663</td>\n",
              "      <td>-0.044381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.177063</td>\n",
              "      <td>-0.492378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93267ccc-eb84-4093-990a-3dbbd4950ea3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93267ccc-eb84-4093-990a-3dbbd4950ea3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93267ccc-eb84-4093-990a-3dbbd4950ea3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmos de Classificação"
      ],
      "metadata": {
        "id": "HVPLyuXVTDbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separação de treino e teste em 70% e 30%"
      ],
      "metadata": {
        "id": "LyLJnD-UTHob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "X_no_cabin = df2.drop('Survived', axis=1)\n",
        "y_no_cabin = df2['Survived']\n",
        "y_no_cabin\n"
      ],
      "metadata": {
        "id": "Ljtvc5fGTNTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33905c4-c2a8-4b48-d754-e1db7582ee95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      0\n",
              "      ..\n",
              "886    0\n",
              "887    1\n",
              "888    0\n",
              "889    1\n",
              "890    0\n",
              "Name: Survived, Length: 891, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mMnNcr0pfTds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "X_train_no_cabin, X_test_no_cabin, y_train_no_cabin, y_test_no_cabin = train_test_split(X_no_cabin, y_no_cabin, test_size=0.3)"
      ],
      "metadata": {
        "id": "fKUbQ0LcTZU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balanceamento de Classes"
      ],
      "metadata": {
        "id": "83WDAkTgUsrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
        "x_train_oversampled_no_cabin, y_train_oversampled_no_cabin = sm.fit_resample(X_train_no_cabin, y_train_no_cabin)"
      ],
      "metadata": {
        "id": "FNKzUKkUUyy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_oversampled_no_cabin.shape)\n",
        "print(x_train_oversampled.shape)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozbGJ9iaU52p",
        "outputId": "a10c4f16-0747-4e31-db43-34d02c37f1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 11)\n",
            "(794, 158)\n",
            "(623, 158)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de ajuste de hiperparâmetros para KNN"
      ],
      "metadata": {
        "id": "H1EPnWlH5F9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "param_grid_KNN = {'n_neighbors': [3, 5, 7],\n",
        "                  'weights': ['uniform', 'distance'],\n",
        "                  'p': [1, 2]}"
      ],
      "metadata": {
        "id": "5Jy-8kdP5KsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV"
      ],
      "metadata": {
        "id": "_rX06kOH_BZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_search = GridSearchCV(estimator = knn, param_grid = param_grid_KNN,\n",
        "                        cv = 10, return_train_score=True)"
      ],
      "metadata": {
        "id": "xzqoPlb2_BZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "_G9XmSHX_BZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_oversampled, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22f31aa-71f9-402d-92f3-8456614084c8",
        "id": "ZLkB2Yfb_BZ7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([397, 397]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_search.fit(x_train_oversampled, y_train_oversampled);\n",
        "print(g_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45849a1-0fbf-41d8-d6ab-363048c91234",
        "id": "KOIEfEIw_BZ7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc214c6c-1261-4df4-a062-7d12f311e465",
        "id": "_uUiR629_BZ7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8363291139240505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ## RandomizedSearchCV"
      ],
      "metadata": {
        "id": "kiAV6ARx_BZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_search = RandomizedSearchCV(estimator = knn, param_distributions = param_grid_KNN,\n",
        "                        n_iter= 10, cv = 10, return_train_score=True)"
      ],
      "metadata": {
        "id": "N9bisoXz_BZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "9rGizKnz_BZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_oversampled, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0caf3dae-627f-4d0e-d641-975672e10266",
        "id": "rhrRXeRx_BZ8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([397, 397]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_search.fit(x_train_oversampled, y_train_oversampled);\n",
        "print(r_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4db441-11bc-4ad0-a539-4a4ac4da1dc8",
        "id": "mFvQmi2Y_BZ8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'weights': 'uniform', 'p': 1, 'n_neighbors': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e2697c-af81-45b1-fe55-4e71289d83f2",
        "id": "0VHtffuv_BZ8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8413765822784811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de ajuste de hiperparâmetros para Random Forest"
      ],
      "metadata": {
        "id": "2kLVliE_dOPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest = RandomForestClassifier()\n",
        "\n",
        "param_grid_RF = {'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "              'max_features':['sqrt','log2'],\n",
        "              'n_estimators': [10, 20, 30, 60]}"
      ],
      "metadata": {
        "id": "hgOSQDZndbCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV"
      ],
      "metadata": {
        "id": "zQEvxmKpdeEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_search = GridSearchCV(estimator = forest, param_grid = param_grid_RF,\n",
        "                        cv = 10, return_train_score=True)"
      ],
      "metadata": {
        "id": "2Qv0eXBqdfiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "7HAqrnOZdo2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_oversampled, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohyMzFuodq45",
        "outputId": "933b365a-b76b-42e8-bcab-4e49fc4929f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([397, 397]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_search.fit(x_train_oversampled, y_train_oversampled);\n",
        "print(g_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEfR9Cm5duV8",
        "outputId": "e981c149-d97c-4450-955c-fe581234f6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 60}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8XJ5YZwdwCo",
        "outputId": "248c7517-ec67-44ff-e4c2-d3b53f68399f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8577056962025316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ## RandomizedSearchCV"
      ],
      "metadata": {
        "id": "6ZngFfDcd_Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_search = RandomizedSearchCV(estimator = forest, param_distributions = param_grid_RF,\n",
        "                        n_iter= 10, cv = 10, return_train_score=True)"
      ],
      "metadata": {
        "id": "yf9vhM_neKrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "cocaJVdveMIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_oversampled, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol5Wt9SLeN7r",
        "outputId": "488fc52e-c87d-47fe-e571-4c15583aa7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([397, 397]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_search.fit(x_train_oversampled, y_train_oversampled);\n",
        "print(r_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpBpT24yePo1",
        "outputId": "ffed3cd8-8d01-4978-a640-9e1b59c061ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 60, 'max_features': 'sqrt', 'criterion': 'gini'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSNWfPLJeRcS",
        "outputId": "c24b0e86-f157-492e-b169-75f29d802b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8501898734177216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de ajuste de hiperparâmetros para Redes Neurais - SciKit"
      ],
      "metadata": {
        "id": "di5Tr_QIGi1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alvo = df['Survived'].values"
      ],
      "metadata": {
        "id": "-BJUHN_7Gi1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = StandardScaler().fit_transform(X)"
      ],
      "metadata": {
        "id": "5nkmQP-T8bpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w_nQCU19LWE",
        "outputId": "031a1494-918e-4169-a5ae-1ff8955a4ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.37695132e-01,  4.32793366e-01, -4.73673609e-01, ...,\n",
              "         9.02587365e-01, -5.92480600e-01, -5.02445171e-01],\n",
              "       [-1.35557354e+00,  4.32793366e-01, -4.73673609e-01, ...,\n",
              "        -1.10792599e+00,  6.38789012e-01,  7.86845294e-01],\n",
              "       [-1.35557354e+00, -4.74545196e-01, -4.73673609e-01, ...,\n",
              "         9.02587365e-01, -2.84663197e-01, -4.88854258e-01],\n",
              "       ...,\n",
              "       [-1.35557354e+00,  4.32793366e-01,  2.00893337e+00, ...,\n",
              "         9.02587365e-01, -2.23290646e-16, -1.76263239e-01],\n",
              "       [ 7.37695132e-01, -4.74545196e-01, -4.73673609e-01, ...,\n",
              "        -1.10792599e+00, -2.84663197e-01, -4.43810379e-02],\n",
              "       [ 7.37695132e-01, -4.74545196e-01, -4.73673609e-01, ...,\n",
              "         9.02587365e-01,  1.77062908e-01, -4.92377828e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_treino, x_teste, y_treino, y_teste = train_test_split(X, alvo, test_size = 0.3, random_state = 0)"
      ],
      "metadata": {
        "id": "QTSdc-sQ9RC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "SYdcy_vv9V9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rna = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, learning_rate='constant', max_iter=1000, tol=0.0001, verbose = True)"
      ],
      "metadata": {
        "id": "Ksvc14dk-re4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rna.fit(x_treino, y_treino)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mXk3cCFz_eli",
        "outputId": "7f696775-e18e-41ab-f59c-fd8cca656e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.82563895\n",
            "Iteration 2, loss = 0.72370159\n",
            "Iteration 3, loss = 0.64625609\n",
            "Iteration 4, loss = 0.58989600\n",
            "Iteration 5, loss = 0.54828118\n",
            "Iteration 6, loss = 0.51559939\n",
            "Iteration 7, loss = 0.49124365\n",
            "Iteration 8, loss = 0.47104467\n",
            "Iteration 9, loss = 0.45388772\n",
            "Iteration 10, loss = 0.43957554\n",
            "Iteration 11, loss = 0.42679190\n",
            "Iteration 12, loss = 0.41637039\n",
            "Iteration 13, loss = 0.40727944\n",
            "Iteration 14, loss = 0.39903490\n",
            "Iteration 15, loss = 0.39218257\n",
            "Iteration 16, loss = 0.38619220\n",
            "Iteration 17, loss = 0.38034907\n",
            "Iteration 18, loss = 0.37523888\n",
            "Iteration 19, loss = 0.37029378\n",
            "Iteration 20, loss = 0.36634830\n",
            "Iteration 21, loss = 0.36246942\n",
            "Iteration 22, loss = 0.35879207\n",
            "Iteration 23, loss = 0.35559164\n",
            "Iteration 24, loss = 0.35225629\n",
            "Iteration 25, loss = 0.34966665\n",
            "Iteration 26, loss = 0.34733110\n",
            "Iteration 27, loss = 0.34452366\n",
            "Iteration 28, loss = 0.34238999\n",
            "Iteration 29, loss = 0.34030654\n",
            "Iteration 30, loss = 0.33849879\n",
            "Iteration 31, loss = 0.33662001\n",
            "Iteration 32, loss = 0.33507231\n",
            "Iteration 33, loss = 0.33321133\n",
            "Iteration 34, loss = 0.33185403\n",
            "Iteration 35, loss = 0.33040335\n",
            "Iteration 36, loss = 0.32918802\n",
            "Iteration 37, loss = 0.32804617\n",
            "Iteration 38, loss = 0.32718234\n",
            "Iteration 39, loss = 0.32620275\n",
            "Iteration 40, loss = 0.32514434\n",
            "Iteration 41, loss = 0.32421208\n",
            "Iteration 42, loss = 0.32291579\n",
            "Iteration 43, loss = 0.32180301\n",
            "Iteration 44, loss = 0.32075878\n",
            "Iteration 45, loss = 0.31999967\n",
            "Iteration 46, loss = 0.31915441\n",
            "Iteration 47, loss = 0.31841437\n",
            "Iteration 48, loss = 0.31757558\n",
            "Iteration 49, loss = 0.31709316\n",
            "Iteration 50, loss = 0.31625803\n",
            "Iteration 51, loss = 0.31587155\n",
            "Iteration 52, loss = 0.31516955\n",
            "Iteration 53, loss = 0.31447053\n",
            "Iteration 54, loss = 0.31377608\n",
            "Iteration 55, loss = 0.31302612\n",
            "Iteration 56, loss = 0.31215226\n",
            "Iteration 57, loss = 0.31160055\n",
            "Iteration 58, loss = 0.31094723\n",
            "Iteration 59, loss = 0.31048512\n",
            "Iteration 60, loss = 0.30979415\n",
            "Iteration 61, loss = 0.30933577\n",
            "Iteration 62, loss = 0.30925485\n",
            "Iteration 63, loss = 0.30897137\n",
            "Iteration 64, loss = 0.30842919\n",
            "Iteration 65, loss = 0.30788320\n",
            "Iteration 66, loss = 0.30744180\n",
            "Iteration 67, loss = 0.30717891\n",
            "Iteration 68, loss = 0.30655854\n",
            "Iteration 69, loss = 0.30608304\n",
            "Iteration 70, loss = 0.30551626\n",
            "Iteration 71, loss = 0.30489647\n",
            "Iteration 72, loss = 0.30448202\n",
            "Iteration 73, loss = 0.30391621\n",
            "Iteration 74, loss = 0.30360777\n",
            "Iteration 75, loss = 0.30344702\n",
            "Iteration 76, loss = 0.30319544\n",
            "Iteration 77, loss = 0.30303826\n",
            "Iteration 78, loss = 0.30284975\n",
            "Iteration 79, loss = 0.30243693\n",
            "Iteration 80, loss = 0.30254366\n",
            "Iteration 81, loss = 0.30247695\n",
            "Iteration 82, loss = 0.30180985\n",
            "Iteration 83, loss = 0.30137473\n",
            "Iteration 84, loss = 0.30116056\n",
            "Iteration 85, loss = 0.30073488\n",
            "Iteration 86, loss = 0.30036078\n",
            "Iteration 87, loss = 0.29994756\n",
            "Iteration 88, loss = 0.29950436\n",
            "Iteration 89, loss = 0.29998049\n",
            "Iteration 90, loss = 0.29914036\n",
            "Iteration 91, loss = 0.29857989\n",
            "Iteration 92, loss = 0.29827308\n",
            "Iteration 93, loss = 0.29795237\n",
            "Iteration 94, loss = 0.29752866\n",
            "Iteration 95, loss = 0.29746795\n",
            "Iteration 96, loss = 0.29718073\n",
            "Iteration 97, loss = 0.29708300\n",
            "Iteration 98, loss = 0.29696165\n",
            "Iteration 99, loss = 0.29649455\n",
            "Iteration 100, loss = 0.29604102\n",
            "Iteration 101, loss = 0.29568184\n",
            "Iteration 102, loss = 0.29525917\n",
            "Iteration 103, loss = 0.29498917\n",
            "Iteration 104, loss = 0.29461741\n",
            "Iteration 105, loss = 0.29453004\n",
            "Iteration 106, loss = 0.29496712\n",
            "Iteration 107, loss = 0.29508929\n",
            "Iteration 108, loss = 0.29504163\n",
            "Iteration 109, loss = 0.29470288\n",
            "Iteration 110, loss = 0.29419484\n",
            "Iteration 111, loss = 0.29484422\n",
            "Iteration 112, loss = 0.29409690\n",
            "Iteration 113, loss = 0.29382274\n",
            "Iteration 114, loss = 0.29289238\n",
            "Iteration 115, loss = 0.29263192\n",
            "Iteration 116, loss = 0.29277153\n",
            "Iteration 117, loss = 0.29288409\n",
            "Iteration 118, loss = 0.29275754\n",
            "Iteration 119, loss = 0.29244482\n",
            "Iteration 120, loss = 0.29184622\n",
            "Iteration 121, loss = 0.29160927\n",
            "Iteration 122, loss = 0.29116043\n",
            "Iteration 123, loss = 0.29069654\n",
            "Iteration 124, loss = 0.29033122\n",
            "Iteration 125, loss = 0.29004555\n",
            "Iteration 126, loss = 0.29041923\n",
            "Iteration 127, loss = 0.29027786\n",
            "Iteration 128, loss = 0.29017253\n",
            "Iteration 129, loss = 0.29057169\n",
            "Iteration 130, loss = 0.29017097\n",
            "Iteration 131, loss = 0.28968715\n",
            "Iteration 132, loss = 0.28885787\n",
            "Iteration 133, loss = 0.28889687\n",
            "Iteration 134, loss = 0.28888298\n",
            "Iteration 135, loss = 0.28849598\n",
            "Iteration 136, loss = 0.28795120\n",
            "Iteration 137, loss = 0.28775298\n",
            "Iteration 138, loss = 0.28723355\n",
            "Iteration 139, loss = 0.28706671\n",
            "Iteration 140, loss = 0.28682664\n",
            "Iteration 141, loss = 0.28680165\n",
            "Iteration 142, loss = 0.28671371\n",
            "Iteration 143, loss = 0.28647473\n",
            "Iteration 144, loss = 0.28645576\n",
            "Iteration 145, loss = 0.28591540\n",
            "Iteration 146, loss = 0.28550837\n",
            "Iteration 147, loss = 0.28536419\n",
            "Iteration 148, loss = 0.28499970\n",
            "Iteration 149, loss = 0.28502924\n",
            "Iteration 150, loss = 0.28528346\n",
            "Iteration 151, loss = 0.28548107\n",
            "Iteration 152, loss = 0.28572606\n",
            "Iteration 153, loss = 0.28542917\n",
            "Iteration 154, loss = 0.28522182\n",
            "Iteration 155, loss = 0.28519284\n",
            "Iteration 156, loss = 0.28488600\n",
            "Iteration 157, loss = 0.28425871\n",
            "Iteration 158, loss = 0.28397321\n",
            "Iteration 159, loss = 0.28354214\n",
            "Iteration 160, loss = 0.28336570\n",
            "Iteration 161, loss = 0.28344029\n",
            "Iteration 162, loss = 0.28363534\n",
            "Iteration 163, loss = 0.28323826\n",
            "Iteration 164, loss = 0.28277166\n",
            "Iteration 165, loss = 0.28278554\n",
            "Iteration 166, loss = 0.28237178\n",
            "Iteration 167, loss = 0.28241736\n",
            "Iteration 168, loss = 0.28229345\n",
            "Iteration 169, loss = 0.28247002\n",
            "Iteration 170, loss = 0.28284852\n",
            "Iteration 171, loss = 0.28252906\n",
            "Iteration 172, loss = 0.28205635\n",
            "Iteration 173, loss = 0.28193102\n",
            "Iteration 174, loss = 0.28198246\n",
            "Iteration 175, loss = 0.28196425\n",
            "Iteration 176, loss = 0.28185051\n",
            "Iteration 177, loss = 0.28184693\n",
            "Iteration 178, loss = 0.28161978\n",
            "Iteration 179, loss = 0.28127987\n",
            "Iteration 180, loss = 0.28068200\n",
            "Iteration 181, loss = 0.28037869\n",
            "Iteration 182, loss = 0.28093973\n",
            "Iteration 183, loss = 0.28060718\n",
            "Iteration 184, loss = 0.27989705\n",
            "Iteration 185, loss = 0.27994986\n",
            "Iteration 186, loss = 0.27936751\n",
            "Iteration 187, loss = 0.27913302\n",
            "Iteration 188, loss = 0.27889585\n",
            "Iteration 189, loss = 0.27895647\n",
            "Iteration 190, loss = 0.27914078\n",
            "Iteration 191, loss = 0.27880882\n",
            "Iteration 192, loss = 0.27856784\n",
            "Iteration 193, loss = 0.27849569\n",
            "Iteration 194, loss = 0.27774563\n",
            "Iteration 195, loss = 0.27783645\n",
            "Iteration 196, loss = 0.27860950\n",
            "Iteration 197, loss = 0.27877947\n",
            "Iteration 198, loss = 0.27828354\n",
            "Iteration 199, loss = 0.27702629\n",
            "Iteration 200, loss = 0.27711844\n",
            "Iteration 201, loss = 0.27699328\n",
            "Iteration 202, loss = 0.27651713\n",
            "Iteration 203, loss = 0.27729974\n",
            "Iteration 204, loss = 0.27689602\n",
            "Iteration 205, loss = 0.27666327\n",
            "Iteration 206, loss = 0.27600214\n",
            "Iteration 207, loss = 0.27618008\n",
            "Iteration 208, loss = 0.27687846\n",
            "Iteration 209, loss = 0.27736896\n",
            "Iteration 210, loss = 0.27629097\n",
            "Iteration 211, loss = 0.27558447\n",
            "Iteration 212, loss = 0.27574671\n",
            "Iteration 213, loss = 0.27560372\n",
            "Iteration 214, loss = 0.27567252\n",
            "Iteration 215, loss = 0.27548873\n",
            "Iteration 216, loss = 0.27546007\n",
            "Iteration 217, loss = 0.27524365\n",
            "Iteration 218, loss = 0.27477943\n",
            "Iteration 219, loss = 0.27437527\n",
            "Iteration 220, loss = 0.27422426\n",
            "Iteration 221, loss = 0.27563851\n",
            "Iteration 222, loss = 0.27546418\n",
            "Iteration 223, loss = 0.27441528\n",
            "Iteration 224, loss = 0.27400365\n",
            "Iteration 225, loss = 0.27364936\n",
            "Iteration 226, loss = 0.27421740\n",
            "Iteration 227, loss = 0.27421067\n",
            "Iteration 228, loss = 0.27374628\n",
            "Iteration 229, loss = 0.27314625\n",
            "Iteration 230, loss = 0.27324266\n",
            "Iteration 231, loss = 0.27350489\n",
            "Iteration 232, loss = 0.27338596\n",
            "Iteration 233, loss = 0.27327928\n",
            "Iteration 234, loss = 0.27292477\n",
            "Iteration 235, loss = 0.27276493\n",
            "Iteration 236, loss = 0.27215241\n",
            "Iteration 237, loss = 0.27247482\n",
            "Iteration 238, loss = 0.27203687\n",
            "Iteration 239, loss = 0.27165757\n",
            "Iteration 240, loss = 0.27131259\n",
            "Iteration 241, loss = 0.27124332\n",
            "Iteration 242, loss = 0.27178083\n",
            "Iteration 243, loss = 0.27192092\n",
            "Iteration 244, loss = 0.27189299\n",
            "Iteration 245, loss = 0.27178567\n",
            "Iteration 246, loss = 0.27197712\n",
            "Iteration 247, loss = 0.27261788\n",
            "Iteration 248, loss = 0.27396415\n",
            "Iteration 249, loss = 0.27416135\n",
            "Iteration 250, loss = 0.27340966\n",
            "Iteration 251, loss = 0.27209630\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(max_iter=1000, verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(max_iter=1000, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=1000, verbose=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes = rna.predict(x_teste)"
      ],
      "metadata": {
        "id": "26NHF0BCAQWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuvJPTVKASUl",
        "outputId": "d1d6efbe-2ecb-4674-815f-ff806ca4af3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "rEYzxcrpAVlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8rjCRA7CwLV",
        "outputId": "e336a1eb-3f85-4968-c46c-14c4b993ffb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 82.46%\n"
          ]
        }
      ],
      "source": [
        "print(\"Acurácia: %.2f%%\" % (accuracy_score(y_teste, previsoes) * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_xxZiTXKeG3",
        "outputId": "292986ba-ee3f-4bdc-b912-7a13ad68c105"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[147,  21],\n",
              "       [ 26,  74]])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "confusion_matrix(y_teste, previsoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZMZ_zPNKzqW",
        "outputId": "ae6b5ba1-87d7-427f-d2c7-27aed39b627a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       168\n",
            "           1       0.78      0.74      0.76       100\n",
            "\n",
            "    accuracy                           0.82       268\n",
            "   macro avg       0.81      0.81      0.81       268\n",
            "weighted avg       0.82      0.82      0.82       268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_teste, previsoes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes_treino = rna.predict(x_treino)\n",
        "previsoes_treino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pX2hH84AhD2",
        "outputId": "85f2bfda-506a-4f69-f5f8-57a5aadd17dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_treino, previsoes_treino)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROEqxnI5AjiM",
        "outputId": "83e8e920-2927-438e-f04a-002b6cb2f723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8860353130016051"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_treino, previsoes_treino)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L57xii1BAmo-",
        "outputId": "7be8cb4b-c7ef-4802-ac51-676091964e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[364,  17],\n",
              "       [ 54, 188]])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VALIDAÇÃO CRUZADA"
      ],
      "metadata": {
        "id": "Sh2wJ3XIA13q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import statistics  as sts\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "WyXsxWuEBBA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create StratifiedKFold object.\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "lst_accu_stratified = []\n",
        "\n",
        "rna = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter =800,\n",
        "                              tol=0.0001, random_state = 3)\n",
        "\n",
        "\n",
        "for train_index, test_index in skf.split(x_treino, y_treino):\n",
        "    x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
        "    y_train_fold, y_test_fold = alvo[train_index], alvo[test_index]\n",
        "    rna.fit(x_train_fold, y_train_fold)\n",
        "    lst_accu_stratified.append(rna.score(x_test_fold, y_test_fold))\n",
        "\n",
        "# Print the output.\n",
        "print('Lista de ACC:', lst_accu_stratified)\n",
        "print('\\nMaior ACC:',\n",
        "      max(lst_accu_stratified)*100, '%')\n",
        "print('\\nMenor ACC:',\n",
        "      min(lst_accu_stratified)*100, '%')\n",
        "print('\\nMédia ACC:',\n",
        "      sts.mean(lst_accu_stratified)*100, '%')\n",
        "print('\\nDesvio Padrão:', sts.stdev(lst_accu_stratified))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKV8gS2lA4Fm",
        "outputId": "0d7cfe65-db3e-4170-e8fb-c666cce536e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lista de ACC: [0.746031746031746, 0.7936507936507936, 0.6984126984126984, 0.7903225806451613, 0.7096774193548387, 0.8709677419354839, 0.7741935483870968, 0.7741935483870968, 0.7096774193548387, 0.7258064516129032]\n",
            "\n",
            "Maior ACC: 87.09677419354838 %\n",
            "\n",
            "Menor ACC: 69.84126984126983 %\n",
            "\n",
            "Média ACC: 75.92933947772657 %\n",
            "\n",
            "Desvio Padrão: 0.05268947408628284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epily5gXMZk9"
      },
      "outputs": [],
      "source": [
        "y_pred = rna.predict(x_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csjefPKHMZk9",
        "outputId": "03c7d7b6-7347-4c1b-c58e-2047fbe1eb92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268, 158)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "x_teste.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm4Yb0abMZk9",
        "outputId": "7251a09d-c7f4-49f5-b094-3864ba8083e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8582089552238806"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ],
      "source": [
        "accuracy_score(y_teste,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "D_YoQCKFMZk-",
        "outputId": "c1a75b4d-f515-401c-a3e2-df12d9a58163"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f49bcfe1210>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "cm = confusion_matrix(y_teste, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de ajuste de hiperparâmetros para Redes Neurais - Keras"
      ],
      "metadata": {
        "id": "pxoigMBmCZuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "Rea5een4Cf0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_shape=(len(df.columns)-1,), activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPTfE2bWCyYv",
        "outputId": "8c89be58-86b1-464a-b6fd-e2c8fc826e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100)               15900     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 808       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,717\n",
            "Trainable params: 16,717\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adam optimizer works pretty well for\n",
        "# all kinds of problems and is a good starting point\n",
        "model.compile(optimizer='adam',\n",
        "\n",
        "\t\t\t# MAE error is good for\n",
        "\t\t\t# numerical predictions\n",
        "\t\t\tloss='mae',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nqCb5TiBDOqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = model.fit(x_treino, y_treino,\n",
        "\n",
        "\t\t\t\tvalidation_data=(x_teste, y_teste),\n",
        "\n",
        "\t\t\t\t# it will use 'batch_size' number\n",
        "\t\t\t\t# of examples per example\n",
        "\t\t\t\tbatch_size=50,\n",
        "\t\t\t\tepochs=100, # total epoch\n",
        "\n",
        "\t\t\t\t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSuQLJoqDVW0",
        "outputId": "8309d915-93f2-4ecd-e545-c2094f3782fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 20ms/step - loss: 0.4826 - accuracy: 0.6180 - val_loss: 0.4517 - val_accuracy: 0.6381\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.6421 - val_loss: 0.3920 - val_accuracy: 0.6567\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3467 - accuracy: 0.6886 - val_loss: 0.3476 - val_accuracy: 0.7164\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.7400 - val_loss: 0.3141 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2486 - accuracy: 0.7913 - val_loss: 0.2908 - val_accuracy: 0.7575\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2184 - accuracy: 0.8299 - val_loss: 0.2733 - val_accuracy: 0.7761\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1995 - accuracy: 0.8427 - val_loss: 0.2607 - val_accuracy: 0.7836\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1829 - accuracy: 0.8475 - val_loss: 0.2481 - val_accuracy: 0.7910\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.8555 - val_loss: 0.2400 - val_accuracy: 0.7985\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1629 - accuracy: 0.8636 - val_loss: 0.2325 - val_accuracy: 0.8022\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 0.8668 - val_loss: 0.2272 - val_accuracy: 0.8022\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.8732 - val_loss: 0.2237 - val_accuracy: 0.8060\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1451 - accuracy: 0.8764 - val_loss: 0.2207 - val_accuracy: 0.8097\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1415 - accuracy: 0.8780 - val_loss: 0.2174 - val_accuracy: 0.8022\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1393 - accuracy: 0.8764 - val_loss: 0.2167 - val_accuracy: 0.8060\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.8812 - val_loss: 0.2138 - val_accuracy: 0.8097\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1346 - accuracy: 0.8812 - val_loss: 0.2129 - val_accuracy: 0.8097\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1326 - accuracy: 0.8796 - val_loss: 0.2120 - val_accuracy: 0.8097\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.8812 - val_loss: 0.2103 - val_accuracy: 0.8134\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1300 - accuracy: 0.8812 - val_loss: 0.2079 - val_accuracy: 0.8097\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.8860 - val_loss: 0.2083 - val_accuracy: 0.8134\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1270 - accuracy: 0.8828 - val_loss: 0.2069 - val_accuracy: 0.8097\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.8844 - val_loss: 0.2066 - val_accuracy: 0.8097\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.8876 - val_loss: 0.2056 - val_accuracy: 0.8060\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1244 - accuracy: 0.8876 - val_loss: 0.2047 - val_accuracy: 0.8060\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1238 - accuracy: 0.8892 - val_loss: 0.2045 - val_accuracy: 0.8060\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1239 - accuracy: 0.8828 - val_loss: 0.2017 - val_accuracy: 0.8134\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.8844 - val_loss: 0.2028 - val_accuracy: 0.8060\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.8892 - val_loss: 0.2021 - val_accuracy: 0.8060\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.8892 - val_loss: 0.2009 - val_accuracy: 0.8097\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1211 - accuracy: 0.8876 - val_loss: 0.2004 - val_accuracy: 0.8097\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1213 - accuracy: 0.8860 - val_loss: 0.1978 - val_accuracy: 0.8172\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1207 - accuracy: 0.8876 - val_loss: 0.1990 - val_accuracy: 0.8097\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.8892 - val_loss: 0.1995 - val_accuracy: 0.8097\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1191 - accuracy: 0.8892 - val_loss: 0.1989 - val_accuracy: 0.8097\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.8892 - val_loss: 0.1984 - val_accuracy: 0.8060\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1189 - accuracy: 0.8892 - val_loss: 0.1994 - val_accuracy: 0.8060\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.8876 - val_loss: 0.1976 - val_accuracy: 0.8060\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.8892 - val_loss: 0.1976 - val_accuracy: 0.8060\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.8892 - val_loss: 0.1988 - val_accuracy: 0.8097\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.8876 - val_loss: 0.1956 - val_accuracy: 0.8097\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.8892 - val_loss: 0.1952 - val_accuracy: 0.8097\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.8892 - val_loss: 0.1955 - val_accuracy: 0.8097\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.8892 - val_loss: 0.1965 - val_accuracy: 0.8097\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.8909 - val_loss: 0.1953 - val_accuracy: 0.8060\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.8892 - val_loss: 0.1956 - val_accuracy: 0.8060\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.8892 - val_loss: 0.1947 - val_accuracy: 0.8060\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.8909 - val_loss: 0.1941 - val_accuracy: 0.8060\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.8892 - val_loss: 0.1957 - val_accuracy: 0.8060\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.8925 - val_loss: 0.1964 - val_accuracy: 0.8097\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.8925 - val_loss: 0.1941 - val_accuracy: 0.8097\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.8909 - val_loss: 0.1937 - val_accuracy: 0.8060\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1143 - accuracy: 0.8909 - val_loss: 0.1947 - val_accuracy: 0.8134\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.8941 - val_loss: 0.1937 - val_accuracy: 0.8134\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.8909 - val_loss: 0.1917 - val_accuracy: 0.8209\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.8909 - val_loss: 0.1924 - val_accuracy: 0.8134\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.8941 - val_loss: 0.1943 - val_accuracy: 0.8134\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.8957 - val_loss: 0.1929 - val_accuracy: 0.8134\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.8925 - val_loss: 0.1902 - val_accuracy: 0.8209\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.8925 - val_loss: 0.1921 - val_accuracy: 0.8172\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.8909 - val_loss: 0.1909 - val_accuracy: 0.8134\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1128 - accuracy: 0.8909 - val_loss: 0.1907 - val_accuracy: 0.8134\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.8909 - val_loss: 0.1898 - val_accuracy: 0.8209\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1126 - accuracy: 0.8909 - val_loss: 0.1908 - val_accuracy: 0.8172\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.8925 - val_loss: 0.1917 - val_accuracy: 0.8172\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.8909 - val_loss: 0.1893 - val_accuracy: 0.8172\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.8909 - val_loss: 0.1909 - val_accuracy: 0.8172\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.8941 - val_loss: 0.1907 - val_accuracy: 0.8172\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.8909 - val_loss: 0.1891 - val_accuracy: 0.8172\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.8925 - val_loss: 0.1907 - val_accuracy: 0.8172\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.8941 - val_loss: 0.1908 - val_accuracy: 0.8134\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.8909 - val_loss: 0.1886 - val_accuracy: 0.8172\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.8925 - val_loss: 0.1912 - val_accuracy: 0.8134\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.8941 - val_loss: 0.1888 - val_accuracy: 0.8172\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1111 - accuracy: 0.8909 - val_loss: 0.1885 - val_accuracy: 0.8172\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.8925 - val_loss: 0.1903 - val_accuracy: 0.8134\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.8941 - val_loss: 0.1890 - val_accuracy: 0.8172\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.8941 - val_loss: 0.1884 - val_accuracy: 0.8172\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.8925 - val_loss: 0.1894 - val_accuracy: 0.8134\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.8957 - val_loss: 0.1898 - val_accuracy: 0.8134\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.8909 - val_loss: 0.1875 - val_accuracy: 0.8172\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1112 - accuracy: 0.8941 - val_loss: 0.1898 - val_accuracy: 0.8134\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.8941 - val_loss: 0.1872 - val_accuracy: 0.8172\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.8925 - val_loss: 0.1888 - val_accuracy: 0.8134\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.8925 - val_loss: 0.1880 - val_accuracy: 0.8172\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.8941 - val_loss: 0.1893 - val_accuracy: 0.8134\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.8941 - val_loss: 0.1881 - val_accuracy: 0.8172\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.8925 - val_loss: 0.1876 - val_accuracy: 0.8172\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8941 - val_loss: 0.1888 - val_accuracy: 0.8172\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1099 - accuracy: 0.8941 - val_loss: 0.1888 - val_accuracy: 0.8172\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8925 - val_loss: 0.1879 - val_accuracy: 0.8172\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.8925 - val_loss: 0.1879 - val_accuracy: 0.8172\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.8941 - val_loss: 0.1874 - val_accuracy: 0.8172\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.8941 - val_loss: 0.1881 - val_accuracy: 0.8172\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1097 - accuracy: 0.8925 - val_loss: 0.1851 - val_accuracy: 0.8172\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1099 - accuracy: 0.8941 - val_loss: 0.1888 - val_accuracy: 0.8134\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1094 - accuracy: 0.8941 - val_loss: 0.1881 - val_accuracy: 0.8172\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.8925 - val_loss: 0.1863 - val_accuracy: 0.8134\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1092 - accuracy: 0.8941 - val_loss: 0.1885 - val_accuracy: 0.8134\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1091 - accuracy: 0.8941 - val_loss: 0.1874 - val_accuracy: 0.8172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_teste, y_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQi6qPXd5FVE",
        "outputId": "c922e86e-bef9-4492-aec7-70a20746d7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.8172\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18740640580654144, 0.8171641826629639]"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXbXnI_LMZlX",
        "outputId": "d9cb13ea-5b14-4784-a622-e12220822774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# this will pass the first 3 rows of features\n",
        "# of our data as input to make predictions\n",
        "y_pred = (model.predict(x_teste) > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_teste,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdCNZnz46jAZ",
        "outputId": "b811e54a-d506-4fbc-d408-2741da075fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8171641791044776"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(losses.history)\n",
        "loss_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "CdxbCklP8bC-",
        "outputId": "0774af47-cbcb-41c7-cfaa-6153e08379c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy\n",
              "0   0.482610  0.617977  0.451697      0.638060\n",
              "1   0.410059  0.642055  0.391969      0.656716\n",
              "2   0.346709  0.688604  0.347566      0.716418\n",
              "3   0.291073  0.739968  0.314147      0.750000\n",
              "4   0.248560  0.791332  0.290829      0.757463\n",
              "..       ...       ...       ...           ...\n",
              "95  0.109899  0.894061  0.188821      0.813433\n",
              "96  0.109416  0.894061  0.188118      0.817164\n",
              "97  0.109737  0.892456  0.186318      0.813433\n",
              "98  0.109192  0.894061  0.188511      0.813433\n",
              "99  0.109078  0.894061  0.187406      0.817164\n",
              "\n",
              "[100 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2feaf47d-01bc-407d-b393-f5f778137177\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.482610</td>\n",
              "      <td>0.617977</td>\n",
              "      <td>0.451697</td>\n",
              "      <td>0.638060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.410059</td>\n",
              "      <td>0.642055</td>\n",
              "      <td>0.391969</td>\n",
              "      <td>0.656716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.346709</td>\n",
              "      <td>0.688604</td>\n",
              "      <td>0.347566</td>\n",
              "      <td>0.716418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.291073</td>\n",
              "      <td>0.739968</td>\n",
              "      <td>0.314147</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.248560</td>\n",
              "      <td>0.791332</td>\n",
              "      <td>0.290829</td>\n",
              "      <td>0.757463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.109899</td>\n",
              "      <td>0.894061</td>\n",
              "      <td>0.188821</td>\n",
              "      <td>0.813433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.109416</td>\n",
              "      <td>0.894061</td>\n",
              "      <td>0.188118</td>\n",
              "      <td>0.817164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.109737</td>\n",
              "      <td>0.892456</td>\n",
              "      <td>0.186318</td>\n",
              "      <td>0.813433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.109192</td>\n",
              "      <td>0.894061</td>\n",
              "      <td>0.188511</td>\n",
              "      <td>0.813433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.109078</td>\n",
              "      <td>0.894061</td>\n",
              "      <td>0.187406</td>\n",
              "      <td>0.817164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2feaf47d-01bc-407d-b393-f5f778137177')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2feaf47d-01bc-407d-b393-f5f778137177 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2feaf47d-01bc-407d-b393-f5f778137177');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# history stores the loss/val\n",
        "# loss in each epoch\n",
        "\n",
        "# loss_df is a dataframe which\n",
        "# contains the losses so we can\n",
        "# plot it to visualize our model training\n",
        "loss_df.loc[:,['accuracy','val_accuracy']].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Wb4uNbHvELsa",
        "outputId": "88003ee2-f84d-40c9-f4d3-019c77cca448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 185
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de ajuste de hiperparâmetros para Decision Tree"
      ],
      "metadata": {
        "id": "Rk4K6B2ysXjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "param_grid_DT = {'criterion': ['gini', 'entropy','log_loss'],\n",
        "              'splitter': ['best','random'],\n",
        "              'max_depth': [None, 5, 10, 15],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 2, 4],\n",
        "              }"
      ],
      "metadata": {
        "id": "6qTkf6YQmnTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV"
      ],
      "metadata": {
        "id": "VSPYg8z_sToG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_search = GridSearchCV(estimator = tree, param_grid = param_grid_DT,\n",
        "                        cv = 10, return_train_score=True)"
      ],
      "metadata": {
        "id": "BYiOBLllsToM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "1y99VbRosToM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_oversampled, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "266a5935-ebbc-40e5-d8aa-9806ca6930e6",
        "id": "sSJPVm0PsToM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([397, 397]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_search.fit(x_train_oversampled, y_train_oversampled);\n",
        "print(g_search.best_params_)"
      ],
      "metadata": {
        "id": "RoAKGARFsToN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e60cd9-e3ab-4f25-c6f3-a229bfe478af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g_search.cv_results_)"
      ],
      "metadata": {
        "id": "UqSztkmXsToN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aae0d2d-9bf3-4139-8d0f-e07017713f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean_fit_time': array([0.01234078, 0.01044159, 0.01190209, 0.0095926 , 0.01085556,\n",
            "       0.00939503, 0.01123974, 0.00984952, 0.01141195, 0.00990424,\n",
            "       0.01119113, 0.00953603, 0.01157482, 0.0092515 , 0.01052258,\n",
            "       0.00555902, 0.00672011, 0.00609522, 0.00625231, 0.00505173,\n",
            "       0.00592146, 0.00531051, 0.00647283, 0.0054913 , 0.00639863,\n",
            "       0.00594928, 0.0061049 , 0.00559685, 0.00615981, 0.00543511,\n",
            "       0.00631518, 0.005461  , 0.00610125, 0.0058342 , 0.00606012,\n",
            "       0.005353  , 0.00671892, 0.00597663, 0.00741987, 0.00576541,\n",
            "       0.00698516, 0.00581474, 0.00700364, 0.00546534, 0.00654716,\n",
            "       0.00581791, 0.00691772, 0.00569246, 0.0067374 , 0.00549507,\n",
            "       0.00675626, 0.0055012 , 0.00647843, 0.00549092, 0.00742598,\n",
            "       0.00618324, 0.00736959, 0.00641785, 0.00689545, 0.00591657,\n",
            "       0.00683265, 0.00620391, 0.00804429, 0.00605803, 0.00684452,\n",
            "       0.00594742, 0.00697575, 0.00591979, 0.00670857, 0.00623465,\n",
            "       0.00705614, 0.00555122, 0.00745547, 0.00671363, 0.00711555,\n",
            "       0.00619621, 0.00720975, 0.00654755, 0.00754817, 0.00671959,\n",
            "       0.00761459, 0.00598009, 0.00747821, 0.00570517, 0.0075443 ,\n",
            "       0.00628357, 0.00674539, 0.00634356, 0.00701509, 0.00552332,\n",
            "       0.00764725, 0.00852072, 0.01045063, 0.0086822 , 0.01003609,\n",
            "       0.00858681, 0.01023045, 0.0084481 , 0.01035223, 0.00846305,\n",
            "       0.01009405, 0.00880623, 0.01093121, 0.00865183, 0.01002502,\n",
            "       0.00831571, 0.01050241, 0.00908437, 0.01204979, 0.00873713,\n",
            "       0.01099172, 0.00570765, 0.00676908, 0.0058985 , 0.00679517,\n",
            "       0.0053663 , 0.00653286, 0.00533442, 0.00643594, 0.00534041,\n",
            "       0.00745614, 0.00603333, 0.00677624, 0.00545192, 0.0066808 ,\n",
            "       0.00545762, 0.0071435 , 0.00628431, 0.00755606, 0.00620379,\n",
            "       0.0073334 , 0.00581825, 0.0069361 , 0.00565462, 0.00755601,\n",
            "       0.00603862, 0.00705559, 0.00662634, 0.0067853 , 0.0055831 ,\n",
            "       0.00685568, 0.00546815, 0.00662174, 0.00576258, 0.00730941,\n",
            "       0.00649228, 0.00728066, 0.00592666, 0.00682597, 0.00562286,\n",
            "       0.00778425, 0.00578787, 0.00774508, 0.0057739 , 0.00684223,\n",
            "       0.0055284 , 0.00697954, 0.00579488, 0.00679252, 0.00538394,\n",
            "       0.00702057, 0.00550194, 0.00595345, 0.00502872, 0.00606382,\n",
            "       0.00528662, 0.00615857, 0.0053329 , 0.00591216, 0.00595624,\n",
            "       0.00610075, 0.00523009, 0.00604975, 0.00516675, 0.00613685,\n",
            "       0.00547633, 0.00603514, 0.00576134, 0.00633874, 0.00527833,\n",
            "       0.00682623, 0.00569367, 0.00759957, 0.00600889, 0.00709062,\n",
            "       0.00596821, 0.0070282 , 0.00569403, 0.00729265, 0.00878067,\n",
            "       0.01114879, 0.00963635, 0.01085112, 0.0088274 , 0.01124249,\n",
            "       0.00922656, 0.0118211 , 0.00872097, 0.0120101 , 0.01041543,\n",
            "       0.01199694, 0.00979702, 0.01147854, 0.00926135, 0.01158383,\n",
            "       0.00964479, 0.01131942, 0.00927546, 0.00841434, 0.00593975,\n",
            "       0.00655029, 0.00548077, 0.00693357, 0.00588939, 0.00666051,\n",
            "       0.0053616 ]), 'std_fit_time': array([2.22379825e-03, 1.91978052e-03, 9.95264758e-04, 2.31386381e-04,\n",
            "       5.67955125e-04, 4.37375075e-04, 7.07695451e-04, 1.30209965e-03,\n",
            "       6.41233085e-04, 1.38567414e-03, 9.68556755e-04, 6.84976727e-04,\n",
            "       4.68637661e-04, 3.01128974e-04, 1.58504039e-03, 1.74297412e-04,\n",
            "       2.70290040e-04, 9.59037297e-04, 9.12986339e-04, 2.04249740e-04,\n",
            "       2.84734560e-04, 4.20560202e-04, 1.21966722e-03, 4.40586152e-04,\n",
            "       8.44794327e-04, 4.98084835e-04, 3.21389851e-04, 5.90283105e-04,\n",
            "       6.98434215e-04, 4.26505413e-04, 1.03433823e-03, 9.46608387e-04,\n",
            "       1.13045271e-04, 7.29522262e-04, 1.25619263e-04, 2.23799558e-04,\n",
            "       4.70608017e-04, 4.33887934e-04, 1.06832054e-03, 1.53299603e-04,\n",
            "       5.21987524e-04, 7.65809256e-04, 9.27765899e-04, 8.44589563e-05,\n",
            "       3.61895055e-04, 5.47467895e-04, 1.15229713e-03, 7.30710670e-04,\n",
            "       2.20548090e-04, 1.44206429e-04, 7.50547328e-04, 2.49781100e-04,\n",
            "       1.66366265e-04, 2.56001414e-04, 1.20758093e-03, 4.82080247e-04,\n",
            "       7.98998394e-04, 1.89898215e-03, 3.65324490e-04, 3.79922088e-04,\n",
            "       3.21193344e-04, 7.18071065e-04, 1.19079713e-03, 2.67403008e-04,\n",
            "       8.96409965e-04, 1.03607968e-03, 9.21076336e-04, 2.53426304e-04,\n",
            "       2.93025004e-04, 1.11663425e-03, 7.05009166e-04, 1.43263391e-04,\n",
            "       4.48311918e-04, 1.04397433e-03, 2.10580132e-04, 7.37003313e-05,\n",
            "       2.61855321e-04, 9.60711948e-04, 5.32894209e-04, 1.18630056e-03,\n",
            "       8.40976997e-04, 1.45004959e-04, 6.23097270e-04, 1.73043370e-04,\n",
            "       1.07147443e-03, 1.38542654e-03, 9.65156455e-05, 1.18912175e-03,\n",
            "       9.28615276e-04, 1.86278200e-04, 2.20605945e-03, 9.27369967e-04,\n",
            "       4.93649712e-04, 7.81708372e-04, 2.32232650e-04, 1.41447297e-04,\n",
            "       5.42725835e-04, 1.79927267e-04, 6.40861195e-04, 2.75594825e-04,\n",
            "       2.79005857e-04, 1.12285443e-03, 1.65981854e-03, 3.49488348e-04,\n",
            "       3.46318313e-04, 2.36092430e-04, 1.21623787e-03, 1.60230588e-03,\n",
            "       1.05514374e-03, 5.18113270e-04, 1.86797596e-03, 1.78573708e-04,\n",
            "       2.12531280e-04, 1.02867789e-03, 4.85169917e-04, 1.20846918e-04,\n",
            "       2.73530245e-04, 1.98197834e-04, 2.32112433e-04, 1.45593778e-04,\n",
            "       1.34169009e-03, 1.08874863e-03, 1.84121862e-04, 3.75988322e-04,\n",
            "       4.69235870e-04, 9.28367445e-05, 2.66527041e-04, 9.12771293e-04,\n",
            "       3.51591008e-04, 9.20023336e-04, 6.15813750e-04, 1.08241733e-04,\n",
            "       1.15139856e-04, 7.30915930e-05, 9.66873670e-04, 2.36307208e-04,\n",
            "       1.34745653e-04, 1.39130140e-03, 1.47133443e-04, 1.40182372e-04,\n",
            "       1.40480217e-04, 1.30828226e-04, 1.07687272e-04, 7.06361715e-04,\n",
            "       3.49640037e-04, 9.53086500e-04, 7.15984133e-04, 1.38878558e-04,\n",
            "       1.19040408e-04, 1.61847832e-04, 1.00409087e-03, 2.49099326e-04,\n",
            "       1.43816354e-03, 6.07270976e-04, 2.17952016e-04, 1.42109866e-04,\n",
            "       5.42065296e-04, 5.30781492e-04, 4.24093946e-04, 2.60188511e-04,\n",
            "       1.51933218e-03, 1.64268422e-04, 1.19860786e-04, 1.01351847e-04,\n",
            "       2.41154429e-04, 1.66894472e-04, 2.98725720e-04, 4.31772700e-04,\n",
            "       1.19260167e-04, 1.13540923e-03, 5.20464473e-04, 2.07083554e-04,\n",
            "       1.44180026e-04, 1.56323463e-04, 3.96930616e-04, 9.82254328e-04,\n",
            "       2.33497224e-04, 1.06650569e-03, 9.09023249e-04, 1.31038436e-04,\n",
            "       5.85050289e-05, 1.07592047e-04, 1.05392552e-03, 1.46339780e-04,\n",
            "       5.10390475e-04, 8.76430771e-04, 8.25336610e-04, 2.27730239e-04,\n",
            "       1.82984815e-03, 8.50860840e-04, 3.78774332e-04, 1.32080469e-03,\n",
            "       1.33743024e-04, 4.81081772e-04, 1.34187185e-03, 2.26039951e-04,\n",
            "       1.30525223e-03, 3.00203174e-04, 9.94546824e-04, 1.53280455e-03,\n",
            "       9.96472194e-04, 5.50933761e-04, 3.30429834e-04, 2.26765335e-04,\n",
            "       3.48799414e-04, 4.56613544e-04, 2.30403858e-04, 2.58174549e-04,\n",
            "       1.82965524e-03, 8.97716058e-04, 8.43723199e-05, 4.67303699e-04,\n",
            "       7.06897483e-04, 1.05260064e-03, 1.01452403e-04, 2.82405369e-04]), 'mean_score_time': array([0.00484288, 0.00523579, 0.00503249, 0.0049984 , 0.00469241,\n",
            "       0.00464184, 0.0047924 , 0.00487611, 0.00473988, 0.00485063,\n",
            "       0.00477018, 0.00588961, 0.00527244, 0.00497653, 0.00469317,\n",
            "       0.00284886, 0.00308428, 0.00296426, 0.00290008, 0.00262764,\n",
            "       0.00277474, 0.00274763, 0.00325429, 0.00332444, 0.00306075,\n",
            "       0.00344372, 0.00293102, 0.0030097 , 0.00287783, 0.00283527,\n",
            "       0.00322473, 0.00285132, 0.00315819, 0.00325944, 0.00290291,\n",
            "       0.00300465, 0.00302653, 0.00313203, 0.00328965, 0.00307539,\n",
            "       0.00300965, 0.0028795 , 0.0029386 , 0.0028018 , 0.00280802,\n",
            "       0.00294876, 0.00303988, 0.00306189, 0.00307758, 0.00284986,\n",
            "       0.00304954, 0.00281255, 0.00306334, 0.00289059, 0.00319924,\n",
            "       0.00299532, 0.00337272, 0.00295022, 0.00305295, 0.0029597 ,\n",
            "       0.00308368, 0.00343881, 0.00336201, 0.00311711, 0.00286949,\n",
            "       0.00343831, 0.00303943, 0.00302515, 0.00295889, 0.00321636,\n",
            "       0.00319548, 0.00280554, 0.00302756, 0.00309134, 0.00286243,\n",
            "       0.00294175, 0.00302923, 0.00316212, 0.00324678, 0.00337551,\n",
            "       0.00311296, 0.00300794, 0.00319357, 0.00285699, 0.00334775,\n",
            "       0.00300896, 0.0028734 , 0.00299718, 0.00294895, 0.00281689,\n",
            "       0.00355895, 0.00517702, 0.00498195, 0.0046123 , 0.00457361,\n",
            "       0.00469608, 0.00483675, 0.00494123, 0.0049248 , 0.00453258,\n",
            "       0.00472598, 0.00502088, 0.00581834, 0.00487244, 0.00471108,\n",
            "       0.00456226, 0.00466199, 0.00506976, 0.00499732, 0.00444989,\n",
            "       0.00446138, 0.00282962, 0.00287573, 0.00287707, 0.00278659,\n",
            "       0.00268664, 0.00273838, 0.00263376, 0.00270402, 0.00268898,\n",
            "       0.00313148, 0.00306032, 0.00303681, 0.00280375, 0.00285847,\n",
            "       0.00273657, 0.00283437, 0.00298126, 0.00316591, 0.00303218,\n",
            "       0.00310776, 0.00289111, 0.00282366, 0.00276711, 0.00299847,\n",
            "       0.00312078, 0.00303342, 0.0034337 , 0.0027957 , 0.00283618,\n",
            "       0.00291002, 0.00272954, 0.0027528 , 0.00281444, 0.00290518,\n",
            "       0.00302539, 0.0031589 , 0.00272439, 0.00272925, 0.00262382,\n",
            "       0.00302255, 0.00276926, 0.00323386, 0.00287294, 0.00280306,\n",
            "       0.00269601, 0.0029176 , 0.00296056, 0.00291407, 0.00267916,\n",
            "       0.00288186, 0.00282309, 0.00270565, 0.00268607, 0.00276499,\n",
            "       0.00284135, 0.0029768 , 0.00283659, 0.00274451, 0.00306618,\n",
            "       0.00291283, 0.00279298, 0.002812  , 0.00276539, 0.00298941,\n",
            "       0.00275745, 0.00276177, 0.00305221, 0.00295799, 0.0028399 ,\n",
            "       0.00286276, 0.00281198, 0.00329854, 0.00314219, 0.00300517,\n",
            "       0.00313172, 0.00286384, 0.00281556, 0.0030623 , 0.0047967 ,\n",
            "       0.00495961, 0.00528834, 0.00480869, 0.00466321, 0.00496962,\n",
            "       0.00487273, 0.0049978 , 0.00452538, 0.00486267, 0.0048744 ,\n",
            "       0.00482051, 0.00476739, 0.00484724, 0.00471065, 0.00495286,\n",
            "       0.00477138, 0.00497816, 0.00477252, 0.0035161 , 0.00308897,\n",
            "       0.00278718, 0.0027308 , 0.00300529, 0.00291972, 0.00278547,\n",
            "       0.00269198]), 'std_score_time': array([3.34504211e-04, 1.43136154e-03, 4.03641990e-04, 8.45649673e-04,\n",
            "       1.88120605e-04, 1.54643740e-04, 3.74056394e-04, 7.23031388e-04,\n",
            "       2.71061316e-04, 6.96517997e-04, 1.25632846e-04, 1.99233615e-03,\n",
            "       6.69953177e-04, 2.60423959e-04, 1.01350645e-03, 8.91779828e-05,\n",
            "       3.81382488e-04, 1.86980521e-04, 2.24551999e-04, 7.69387837e-05,\n",
            "       1.53217264e-04, 1.55705375e-04, 8.08833097e-04, 9.67135967e-04,\n",
            "       5.82152734e-04, 6.67834579e-04, 1.38843493e-04, 3.13945149e-04,\n",
            "       1.36053067e-04, 9.26798370e-05, 5.87846584e-04, 2.42716063e-04,\n",
            "       5.08437514e-04, 6.83345701e-04, 9.35170580e-05, 2.94753259e-04,\n",
            "       4.88909614e-04, 4.57228669e-04, 4.72643421e-04, 2.14657489e-04,\n",
            "       1.22470971e-04, 3.48932612e-04, 1.88821229e-04, 1.08953284e-04,\n",
            "       1.35784857e-04, 2.12430954e-04, 6.42783147e-04, 6.96048832e-04,\n",
            "       1.67266328e-04, 1.04161189e-04, 2.40222071e-04, 9.59610376e-05,\n",
            "       6.38468637e-04, 2.45952541e-04, 7.07950714e-04, 3.61820458e-04,\n",
            "       5.71751443e-04, 4.32826174e-04, 2.32762993e-04, 2.04357699e-04,\n",
            "       4.50971669e-04, 7.66425455e-04, 4.67690967e-04, 2.48632525e-04,\n",
            "       3.52804854e-04, 1.03951305e-03, 4.75337101e-04, 1.31928623e-04,\n",
            "       1.39736731e-04, 6.02993499e-04, 5.54225696e-04, 3.18925378e-05,\n",
            "       1.49442479e-04, 4.61602703e-04, 9.32696681e-05, 8.11628952e-05,\n",
            "       1.24974792e-04, 4.79729102e-04, 4.63232550e-04, 6.34500202e-04,\n",
            "       1.57870912e-04, 1.37837936e-04, 1.74643352e-04, 1.08186483e-04,\n",
            "       7.26808770e-04, 4.78583847e-04, 1.01677373e-04, 5.25160220e-04,\n",
            "       3.54446194e-04, 8.87247410e-05, 8.90222193e-04, 1.55004882e-03,\n",
            "       6.52941182e-04, 1.17945611e-04, 1.13272436e-04, 1.40527227e-04,\n",
            "       5.92864180e-04, 7.34852954e-04, 5.21630249e-04, 1.71591957e-04,\n",
            "       1.17877618e-04, 1.11625014e-03, 2.81355202e-03, 7.17567461e-04,\n",
            "       1.61397194e-04, 1.47083560e-04, 1.81229357e-04, 1.03508520e-03,\n",
            "       3.11857080e-04, 3.57663229e-04, 8.62529924e-04, 1.39170055e-04,\n",
            "       2.24538943e-04, 5.81697928e-04, 1.50777267e-04, 1.81010369e-04,\n",
            "       1.17059016e-04, 1.13521589e-04, 1.01947921e-04, 7.07977297e-05,\n",
            "       6.03310177e-04, 5.95377666e-04, 1.60011519e-04, 3.38136149e-04,\n",
            "       1.38937864e-04, 8.60591999e-05, 1.22629075e-04, 5.24661566e-04,\n",
            "       2.23768730e-04, 5.17551663e-04, 5.28660569e-04, 1.52260451e-04,\n",
            "       1.11382875e-04, 7.49219109e-05, 1.69967040e-04, 1.87123844e-04,\n",
            "       2.40567098e-04, 8.17500991e-04, 7.17842669e-05, 1.30601937e-04,\n",
            "       1.37574389e-04, 6.12955805e-05, 9.84316785e-05, 1.59057152e-04,\n",
            "       1.37725472e-04, 5.55817970e-04, 8.40005304e-04, 6.73962937e-05,\n",
            "       8.68280433e-05, 1.65714203e-04, 2.46790047e-04, 1.57568364e-04,\n",
            "       5.17281587e-04, 5.48181929e-04, 1.11649639e-04, 5.89183831e-05,\n",
            "       1.58214722e-04, 4.61584616e-04, 4.23186158e-04, 1.60364165e-04,\n",
            "       7.71289330e-04, 9.35071740e-05, 1.05413913e-04, 2.06673508e-04,\n",
            "       1.24426396e-04, 2.31079790e-04, 5.28407202e-04, 3.47596926e-04,\n",
            "       9.65842492e-05, 6.74449434e-04, 5.83654126e-04, 1.37255661e-04,\n",
            "       1.04340219e-04, 2.23308178e-04, 4.69727372e-04, 1.04815283e-04,\n",
            "       1.04366085e-04, 5.60535754e-04, 5.41283019e-04, 1.51275309e-04,\n",
            "       7.96051788e-05, 1.12201468e-04, 6.59726210e-04, 1.35391194e-04,\n",
            "       2.92039096e-04, 5.59372864e-04, 1.27506194e-04, 1.15105470e-04,\n",
            "       6.63626137e-04, 2.97876986e-04, 2.33833631e-04, 1.27546121e-03,\n",
            "       1.57013992e-04, 1.70463697e-04, 6.84056230e-04, 1.21384518e-04,\n",
            "       3.75269784e-04, 6.25121330e-05, 1.87962871e-04, 2.65004820e-04,\n",
            "       3.77812724e-04, 1.77429192e-04, 1.05380947e-04, 1.03153360e-04,\n",
            "       4.26047794e-04, 1.77064321e-04, 6.01331185e-04, 3.71536175e-04,\n",
            "       9.44750154e-04, 7.31437663e-04, 2.72226999e-04, 2.15016624e-04,\n",
            "       7.64356002e-04, 5.55442202e-04, 7.35325919e-05, 1.55357395e-04]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
            "                   'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
            "                   'entropy', 'entropy', 'entropy', 'entropy', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
            "                   'log_loss', 'log_loss', 'log_loss'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_max_depth': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
            "                   None, None, None, None, None, None, None, None, None,\n",
            "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
            "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
            "                   10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
            "                   15, 15, 15, 15, 15, 15, 15, 15, None, None, None, None,\n",
            "                   None, None, None, None, None, None, None, None, None,\n",
            "                   None, None, None, None, None, 5, 5, 5, 5, 5, 5, 5, 5,\n",
            "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
            "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
            "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
            "                   15, 15, None, None, None, None, None, None, None, None,\n",
            "                   None, None, None, None, None, None, None, None, None,\n",
            "                   None, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
            "                   5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
            "                   10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15,\n",
            "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
            "                   1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10,\n",
            "                   10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5,\n",
            "                   10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2,\n",
            "                   5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10,\n",
            "                   2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10,\n",
            "                   10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5,\n",
            "                   10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2,\n",
            "                   5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10,\n",
            "                   2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10,\n",
            "                   10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5,\n",
            "                   10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2,\n",
            "                   5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10,\n",
            "                   2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10, 10, 2, 2, 5, 5, 10,\n",
            "                   10],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_splitter': masked_array(data=['best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random',\n",
            "                   'best', 'random', 'best', 'random', 'best', 'random'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'best'}, {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}], 'split0_test_score': array([0.675 , 0.7375, 0.7125, 0.75  , 0.75  , 0.7625, 0.7375, 0.675 ,\n",
            "       0.7375, 0.775 , 0.7375, 0.825 , 0.75  , 0.75  , 0.7375, 0.75  ,\n",
            "       0.75  , 0.725 , 0.7125, 0.7125, 0.725 , 0.6875, 0.725 , 0.75  ,\n",
            "       0.7125, 0.7   , 0.7125, 0.7   , 0.7125, 0.7375, 0.725 , 0.75  ,\n",
            "       0.725 , 0.725 , 0.725 , 0.75  , 0.7125, 0.825 , 0.725 , 0.825 ,\n",
            "       0.725 , 0.8   , 0.7375, 0.825 , 0.7375, 0.85  , 0.7375, 0.7625,\n",
            "       0.7375, 0.775 , 0.75  , 0.775 , 0.75  , 0.7625, 0.675 , 0.7875,\n",
            "       0.7125, 0.775 , 0.75  , 0.7   , 0.7375, 0.7625, 0.7375, 0.7875,\n",
            "       0.7375, 0.725 , 0.7375, 0.7375, 0.7375, 0.7375, 0.7625, 0.7125,\n",
            "       0.7125, 0.7625, 0.7375, 0.7625, 0.725 , 0.7375, 0.75  , 0.8   ,\n",
            "       0.75  , 0.8375, 0.725 , 0.7875, 0.7375, 0.75  , 0.7375, 0.8   ,\n",
            "       0.7375, 0.7625, 0.775 , 0.6875, 0.775 , 0.725 , 0.775 , 0.7375,\n",
            "       0.7625, 0.775 , 0.7625, 0.7875, 0.7625, 0.75  , 0.7625, 0.7   ,\n",
            "       0.7625, 0.7125, 0.7625, 0.65  , 0.7   , 0.7125, 0.7125, 0.8   ,\n",
            "       0.7   , 0.8125, 0.7125, 0.8   , 0.7125, 0.8   , 0.7   , 0.725 ,\n",
            "       0.7125, 0.7625, 0.7125, 0.7625, 0.7   , 0.7625, 0.7125, 0.7875,\n",
            "       0.7375, 0.75  , 0.7375, 0.7625, 0.75  , 0.725 , 0.75  , 0.7625,\n",
            "       0.725 , 0.75  , 0.7375, 0.7   , 0.7375, 0.6875, 0.7375, 0.725 ,\n",
            "       0.7125, 0.75  , 0.75  , 0.825 , 0.725 , 0.7   , 0.75  , 0.8   ,\n",
            "       0.75  , 0.7625, 0.725 , 0.7375, 0.7375, 0.7375, 0.7375, 0.725 ,\n",
            "       0.7375, 0.8   , 0.775 , 0.6875, 0.775 , 0.7   , 0.775 , 0.7375,\n",
            "       0.7625, 0.725 , 0.7625, 0.725 , 0.7625, 0.6875, 0.7625, 0.7375,\n",
            "       0.7625, 0.7375, 0.7625, 0.75  , 0.6875, 0.725 , 0.7125, 0.825 ,\n",
            "       0.7   , 0.7375, 0.7125, 0.7875, 0.7125, 0.8   , 0.7   , 0.775 ,\n",
            "       0.7125, 0.75  , 0.7125, 0.8375, 0.7   , 0.7   , 0.7125, 0.8125,\n",
            "       0.75  , 0.7875, 0.7375, 0.7625, 0.75  , 0.7625, 0.75  , 0.8   ,\n",
            "       0.725 , 0.8125, 0.7375, 0.7625, 0.7375, 0.85  , 0.7375, 0.8125]), 'split1_test_score': array([0.8125, 0.8125, 0.8125, 0.8625, 0.75  , 0.85  , 0.7625, 0.8   ,\n",
            "       0.775 , 0.8125, 0.7125, 0.825 , 0.7375, 0.7625, 0.7375, 0.8125,\n",
            "       0.75  , 0.825 , 0.7625, 0.7875, 0.7625, 0.7875, 0.7625, 0.8125,\n",
            "       0.7625, 0.875 , 0.7625, 0.775 , 0.7625, 0.775 , 0.7625, 0.8375,\n",
            "       0.7625, 0.8   , 0.7625, 0.7625, 0.7625, 0.8375, 0.7875, 0.85  ,\n",
            "       0.75  , 0.775 , 0.775 , 0.875 , 0.775 , 0.8375, 0.7375, 0.8375,\n",
            "       0.7375, 0.725 , 0.7375, 0.775 , 0.7375, 0.7875, 0.775 , 0.7375,\n",
            "       0.7875, 0.8125, 0.75  , 0.8125, 0.7625, 0.775 , 0.775 , 0.8125,\n",
            "       0.725 , 0.8   , 0.7375, 0.85  , 0.7375, 0.85  , 0.7375, 0.8625,\n",
            "       0.7875, 0.8   , 0.8   , 0.7875, 0.7375, 0.825 , 0.8   , 0.8375,\n",
            "       0.775 , 0.8   , 0.725 , 0.7875, 0.75  , 0.775 , 0.7625, 0.825 ,\n",
            "       0.7625, 0.85  , 0.775 , 0.85  , 0.775 , 0.825 , 0.775 , 0.7625,\n",
            "       0.7625, 0.825 , 0.7625, 0.8375, 0.7625, 0.8125, 0.775 , 0.7875,\n",
            "       0.775 , 0.8   , 0.775 , 0.7625, 0.75  , 0.8375, 0.75  , 0.8   ,\n",
            "       0.725 , 0.775 , 0.725 , 0.8   , 0.725 , 0.8125, 0.7125, 0.85  ,\n",
            "       0.7375, 0.775 , 0.725 , 0.825 , 0.75  , 0.825 , 0.8   , 0.85  ,\n",
            "       0.8125, 0.85  , 0.7375, 0.8125, 0.7875, 0.825 , 0.7875, 0.85  ,\n",
            "       0.7375, 0.7875, 0.75  , 0.7875, 0.7375, 0.8375, 0.7625, 0.8   ,\n",
            "       0.7625, 0.8   , 0.8125, 0.85  , 0.7375, 0.8   , 0.8   , 0.8625,\n",
            "       0.7625, 0.8   , 0.725 , 0.85  , 0.75  , 0.7875, 0.75  , 0.8375,\n",
            "       0.7625, 0.7875, 0.775 , 0.8125, 0.775 , 0.8   , 0.775 , 0.7875,\n",
            "       0.7625, 0.7375, 0.7625, 0.825 , 0.7625, 0.8   , 0.775 , 0.7625,\n",
            "       0.775 , 0.85  , 0.775 , 0.8   , 0.725 , 0.8125, 0.7375, 0.8125,\n",
            "       0.7125, 0.8125, 0.725 , 0.8125, 0.7375, 0.825 , 0.7125, 0.8125,\n",
            "       0.7375, 0.8   , 0.7375, 0.8375, 0.75  , 0.825 , 0.7375, 0.8125,\n",
            "       0.775 , 0.8125, 0.725 , 0.8625, 0.7375, 0.85  , 0.8   , 0.8375,\n",
            "       0.725 , 0.8125, 0.7375, 0.8   , 0.75  , 0.825 , 0.7625, 0.8625]), 'split2_test_score': array([0.7875, 0.8125, 0.7875, 0.8   , 0.8125, 0.7625, 0.8375, 0.8   ,\n",
            "       0.825 , 0.8   , 0.8375, 0.7875, 0.875 , 0.7625, 0.8625, 0.775 ,\n",
            "       0.8625, 0.8   , 0.7875, 0.7625, 0.7875, 0.7875, 0.7875, 0.775 ,\n",
            "       0.8   , 0.8125, 0.8   , 0.8   , 0.8   , 0.7625, 0.8   , 0.8   ,\n",
            "       0.8   , 0.7875, 0.8   , 0.8125, 0.8125, 0.8125, 0.8   , 0.8375,\n",
            "       0.8125, 0.7625, 0.85  , 0.8   , 0.85  , 0.8125, 0.8375, 0.825 ,\n",
            "       0.875 , 0.775 , 0.875 , 0.775 , 0.85  , 0.7875, 0.8   , 0.85  ,\n",
            "       0.8125, 0.8   , 0.8125, 0.8125, 0.8375, 0.775 , 0.8375, 0.8125,\n",
            "       0.8375, 0.8   , 0.8625, 0.825 , 0.875 , 0.825 , 0.85  , 0.825 ,\n",
            "       0.7875, 0.8125, 0.7875, 0.825 , 0.775 , 0.8125, 0.8   , 0.825 ,\n",
            "       0.7875, 0.8375, 0.8   , 0.7625, 0.8125, 0.8375, 0.825 , 0.825 ,\n",
            "       0.8125, 0.775 , 0.7875, 0.8   , 0.7875, 0.8   , 0.7875, 0.7625,\n",
            "       0.8   , 0.8   , 0.8   , 0.8   , 0.8   , 0.825 , 0.8   , 0.7625,\n",
            "       0.8   , 0.8   , 0.8   , 0.8   , 0.8   , 0.8625, 0.7875, 0.8125,\n",
            "       0.775 , 0.8   , 0.8125, 0.825 , 0.8125, 0.85  , 0.8125, 0.85  ,\n",
            "       0.85  , 0.825 , 0.8375, 0.8625, 0.8375, 0.8   , 0.8   , 0.8625,\n",
            "       0.7875, 0.875 , 0.7625, 0.825 , 0.8125, 0.7625, 0.8125, 0.8375,\n",
            "       0.8125, 0.8125, 0.825 , 0.8625, 0.825 , 0.8   , 0.8125, 0.775 ,\n",
            "       0.8125, 0.8125, 0.775 , 0.85  , 0.775 , 0.8125, 0.7875, 0.8   ,\n",
            "       0.7875, 0.85  , 0.8   , 0.8   , 0.8125, 0.8375, 0.825 , 0.8   ,\n",
            "       0.8   , 0.85  , 0.7875, 0.8125, 0.7875, 0.8   , 0.7875, 0.8   ,\n",
            "       0.8   , 0.7375, 0.8   , 0.775 , 0.8   , 0.8125, 0.8   , 0.7875,\n",
            "       0.8   , 0.8   , 0.8   , 0.8125, 0.8   , 0.8375, 0.7875, 0.8125,\n",
            "       0.7875, 0.8375, 0.8125, 0.8125, 0.8125, 0.825 , 0.8   , 0.8125,\n",
            "       0.8375, 0.8125, 0.8375, 0.775 , 0.825 , 0.8375, 0.775 , 0.8375,\n",
            "       0.7875, 0.7625, 0.7875, 0.825 , 0.8   , 0.8125, 0.8   , 0.8625,\n",
            "       0.7875, 0.7875, 0.8375, 0.8   , 0.8375, 0.775 , 0.8125, 0.8375]), 'split3_test_score': array([0.7625, 0.8375, 0.7875, 0.7875, 0.8125, 0.725 , 0.75  , 0.775 ,\n",
            "       0.775 , 0.7875, 0.8   , 0.775 , 0.7875, 0.8   , 0.8125, 0.7625,\n",
            "       0.8125, 0.7875, 0.7875, 0.8125, 0.7875, 0.775 , 0.7875, 0.7875,\n",
            "       0.7875, 0.775 , 0.7875, 0.7875, 0.7875, 0.7875, 0.7875, 0.8125,\n",
            "       0.7875, 0.7625, 0.7875, 0.775 , 0.7875, 0.8   , 0.8   , 0.8375,\n",
            "       0.825 , 0.8   , 0.8125, 0.8125, 0.8125, 0.7375, 0.825 , 0.8375,\n",
            "       0.825 , 0.8375, 0.8125, 0.85  , 0.8375, 0.825 , 0.7625, 0.85  ,\n",
            "       0.775 , 0.7875, 0.825 , 0.8625, 0.775 , 0.7375, 0.775 , 0.7875,\n",
            "       0.8   , 0.825 , 0.8   , 0.8   , 0.775 , 0.8375, 0.8125, 0.8125,\n",
            "       0.8   , 0.8   , 0.8125, 0.7625, 0.825 , 0.7625, 0.775 , 0.75  ,\n",
            "       0.775 , 0.7875, 0.8125, 0.7625, 0.8125, 0.7875, 0.8125, 0.75  ,\n",
            "       0.825 , 0.775 , 0.8125, 0.8   , 0.8125, 0.7625, 0.8125, 0.725 ,\n",
            "       0.8125, 0.825 , 0.8125, 0.7625, 0.8125, 0.825 , 0.8125, 0.775 ,\n",
            "       0.8125, 0.775 , 0.8125, 0.8   , 0.7875, 0.825 , 0.7875, 0.775 ,\n",
            "       0.8125, 0.85  , 0.775 , 0.8125, 0.775 , 0.8   , 0.8   , 0.8375,\n",
            "       0.8   , 0.8   , 0.8   , 0.775 , 0.825 , 0.8375, 0.8   , 0.8125,\n",
            "       0.8   , 0.775 , 0.825 , 0.8   , 0.7875, 0.8125, 0.7875, 0.75  ,\n",
            "       0.8125, 0.8125, 0.8   , 0.8375, 0.8   , 0.8   , 0.8125, 0.825 ,\n",
            "       0.8   , 0.775 , 0.8125, 0.75  , 0.825 , 0.8125, 0.775 , 0.7375,\n",
            "       0.775 , 0.775 , 0.8125, 0.85  , 0.8125, 0.7875, 0.8125, 0.7875,\n",
            "       0.825 , 0.775 , 0.8125, 0.825 , 0.8125, 0.7625, 0.8125, 0.75  ,\n",
            "       0.8125, 0.7625, 0.8125, 0.7375, 0.8125, 0.7875, 0.8125, 0.7875,\n",
            "       0.8125, 0.825 , 0.8125, 0.825 , 0.7875, 0.8375, 0.7875, 0.8   ,\n",
            "       0.8125, 0.85  , 0.775 , 0.75  , 0.775 , 0.7625, 0.8   , 0.8375,\n",
            "       0.8125, 0.8   , 0.8125, 0.825 , 0.8125, 0.7875, 0.8   , 0.8   ,\n",
            "       0.8   , 0.7875, 0.825 , 0.775 , 0.7875, 0.775 , 0.8   , 0.8   ,\n",
            "       0.8125, 0.7875, 0.8125, 0.7875, 0.8   , 0.825 , 0.8125, 0.7875]), 'split4_test_score': array([0.82278481, 0.78481013, 0.79746835, 0.75949367, 0.81012658,\n",
            "       0.72151899, 0.79746835, 0.70886076, 0.81012658, 0.72151899,\n",
            "       0.81012658, 0.78481013, 0.78481013, 0.81012658, 0.78481013,\n",
            "       0.74683544, 0.78481013, 0.75949367, 0.78481013, 0.7721519 ,\n",
            "       0.78481013, 0.75949367, 0.78481013, 0.79746835, 0.78481013,\n",
            "       0.74683544, 0.78481013, 0.6835443 , 0.78481013, 0.73417722,\n",
            "       0.78481013, 0.70886076, 0.78481013, 0.81012658, 0.78481013,\n",
            "       0.74683544, 0.82278481, 0.75949367, 0.82278481, 0.7721519 ,\n",
            "       0.82278481, 0.78481013, 0.83544304, 0.7721519 , 0.82278481,\n",
            "       0.74683544, 0.82278481, 0.72151899, 0.81012658, 0.73417722,\n",
            "       0.81012658, 0.78481013, 0.81012658, 0.73417722, 0.83544304,\n",
            "       0.7721519 , 0.82278481, 0.78481013, 0.81012658, 0.70886076,\n",
            "       0.81012658, 0.74683544, 0.81012658, 0.82278481, 0.79746835,\n",
            "       0.74683544, 0.78481013, 0.73417722, 0.78481013, 0.74683544,\n",
            "       0.78481013, 0.70886076, 0.82278481, 0.72151899, 0.81012658,\n",
            "       0.79746835, 0.79746835, 0.75949367, 0.79746835, 0.72151899,\n",
            "       0.79746835, 0.7721519 , 0.78481013, 0.74683544, 0.78481013,\n",
            "       0.7721519 , 0.78481013, 0.72151899, 0.78481013, 0.75949367,\n",
            "       0.81012658, 0.78481013, 0.81012658, 0.72151899, 0.81012658,\n",
            "       0.72151899, 0.79746835, 0.73417722, 0.79746835, 0.72151899,\n",
            "       0.79746835, 0.74683544, 0.81012658, 0.73417722, 0.81012658,\n",
            "       0.72151899, 0.81012658, 0.6835443 , 0.78481013, 0.7721519 ,\n",
            "       0.79746835, 0.78481013, 0.81012658, 0.7721519 , 0.78481013,\n",
            "       0.73417722, 0.78481013, 0.74683544, 0.79746835, 0.73417722,\n",
            "       0.78481013, 0.74683544, 0.78481013, 0.75949367, 0.78481013,\n",
            "       0.72151899, 0.79746835, 0.74683544, 0.78481013, 0.78481013,\n",
            "       0.83544304, 0.74683544, 0.79746835, 0.78481013, 0.78481013,\n",
            "       0.75949367, 0.82278481, 0.81012658, 0.78481013, 0.73417722,\n",
            "       0.78481013, 0.78481013, 0.78481013, 0.75949367, 0.7721519 ,\n",
            "       0.79746835, 0.78481013, 0.67088608, 0.81012658, 0.74683544,\n",
            "       0.79746835, 0.78481013, 0.79746835, 0.72151899, 0.78481013,\n",
            "       0.72151899, 0.78481013, 0.73417722, 0.78481013, 0.7721519 ,\n",
            "       0.78481013, 0.7721519 , 0.81012658, 0.75949367, 0.81012658,\n",
            "       0.74683544, 0.81012658, 0.81012658, 0.79746835, 0.72151899,\n",
            "       0.79746835, 0.70886076, 0.79746835, 0.75949367, 0.81012658,\n",
            "       0.78481013, 0.81012658, 0.81012658, 0.81012658, 0.75949367,\n",
            "       0.79746835, 0.79746835, 0.7721519 , 0.74683544, 0.82278481,\n",
            "       0.72151899, 0.78481013, 0.78481013, 0.7721519 , 0.70886076,\n",
            "       0.79746835, 0.7721519 , 0.78481013, 0.69620253, 0.78481013,\n",
            "       0.7721519 , 0.78481013, 0.75949367, 0.81012658, 0.70886076,\n",
            "       0.79746835, 0.75949367, 0.82278481, 0.73417722, 0.79746835,\n",
            "       0.72151899, 0.7721519 , 0.7721519 , 0.82278481, 0.75949367,\n",
            "       0.7721519 , 0.74683544, 0.78481013, 0.74683544, 0.78481013,\n",
            "       0.73417722]), 'split5_test_score': array([0.7721519 , 0.74683544, 0.78481013, 0.78481013, 0.75949367,\n",
            "       0.79746835, 0.7721519 , 0.79746835, 0.7721519 , 0.81012658,\n",
            "       0.74683544, 0.78481013, 0.7721519 , 0.72151899, 0.75949367,\n",
            "       0.74683544, 0.74683544, 0.78481013, 0.73417722, 0.75949367,\n",
            "       0.74683544, 0.78481013, 0.74683544, 0.75949367, 0.74683544,\n",
            "       0.72151899, 0.74683544, 0.78481013, 0.74683544, 0.74683544,\n",
            "       0.74683544, 0.79746835, 0.74683544, 0.78481013, 0.74683544,\n",
            "       0.69620253, 0.81012658, 0.75949367, 0.79746835, 0.78481013,\n",
            "       0.7721519 , 0.72151899, 0.79746835, 0.75949367, 0.75949367,\n",
            "       0.79746835, 0.75949367, 0.7721519 , 0.79746835, 0.74683544,\n",
            "       0.75949367, 0.73417722, 0.78481013, 0.74683544, 0.79746835,\n",
            "       0.7721519 , 0.79746835, 0.81012658, 0.74683544, 0.79746835,\n",
            "       0.75949367, 0.78481013, 0.7721519 , 0.82278481, 0.7721519 ,\n",
            "       0.78481013, 0.7721519 , 0.73417722, 0.79746835, 0.72151899,\n",
            "       0.75949367, 0.73417722, 0.7721519 , 0.79746835, 0.79746835,\n",
            "       0.81012658, 0.81012658, 0.78481013, 0.79746835, 0.81012658,\n",
            "       0.79746835, 0.73417722, 0.81012658, 0.7721519 , 0.7721519 ,\n",
            "       0.73417722, 0.75949367, 0.7721519 , 0.78481013, 0.81012658,\n",
            "       0.74683544, 0.73417722, 0.75949367, 0.75949367, 0.75949367,\n",
            "       0.74683544, 0.74683544, 0.74683544, 0.74683544, 0.70886076,\n",
            "       0.74683544, 0.72151899, 0.75949367, 0.81012658, 0.75949367,\n",
            "       0.74683544, 0.75949367, 0.7721519 , 0.78481013, 0.79746835,\n",
            "       0.74683544, 0.73417722, 0.78481013, 0.81012658, 0.75949367,\n",
            "       0.78481013, 0.78481013, 0.78481013, 0.78481013, 0.74683544,\n",
            "       0.73417722, 0.74683544, 0.73417722, 0.7721519 , 0.78481013,\n",
            "       0.72151899, 0.78481013, 0.7721519 , 0.78481013, 0.79746835,\n",
            "       0.81012658, 0.72151899, 0.7721519 , 0.79746835, 0.79746835,\n",
            "       0.78481013, 0.81012658, 0.73417722, 0.7721519 , 0.7721519 ,\n",
            "       0.7721519 , 0.79746835, 0.79746835, 0.7721519 , 0.7721519 ,\n",
            "       0.7721519 , 0.79746835, 0.78481013, 0.81012658, 0.73417722,\n",
            "       0.81012658, 0.79746835, 0.78481013, 0.78481013, 0.81012658,\n",
            "       0.75949367, 0.75949367, 0.74683544, 0.7721519 , 0.75949367,\n",
            "       0.79746835, 0.73417722, 0.75949367, 0.74683544, 0.75949367,\n",
            "       0.75949367, 0.75949367, 0.7721519 , 0.74683544, 0.73417722,\n",
            "       0.74683544, 0.72151899, 0.74683544, 0.7721519 , 0.75949367,\n",
            "       0.70886076, 0.75949367, 0.72151899, 0.75949367, 0.81012658,\n",
            "       0.75949367, 0.79746835, 0.74683544, 0.81012658, 0.78481013,\n",
            "       0.7721519 , 0.75949367, 0.7721519 , 0.78481013, 0.7721519 ,\n",
            "       0.75949367, 0.75949367, 0.74683544, 0.7721519 , 0.7721519 ,\n",
            "       0.73417722, 0.74683544, 0.74683544, 0.7721519 , 0.7721519 ,\n",
            "       0.79746835, 0.78481013, 0.81012658, 0.78481013, 0.78481013,\n",
            "       0.79746835, 0.79746835, 0.78481013, 0.81012658, 0.73417722,\n",
            "       0.78481013, 0.73417722, 0.78481013, 0.78481013, 0.79746835,\n",
            "       0.74683544]), 'split6_test_score': array([0.86075949, 0.91139241, 0.86075949, 0.86075949, 0.91139241,\n",
            "       0.88607595, 0.86075949, 0.91139241, 0.88607595, 0.89873418,\n",
            "       0.88607595, 0.94936709, 0.86075949, 0.92405063, 0.86075949,\n",
            "       0.91139241, 0.86075949, 0.88607595, 0.87341772, 0.87341772,\n",
            "       0.87341772, 0.86075949, 0.88607595, 0.87341772, 0.87341772,\n",
            "       0.88607595, 0.87341772, 0.87341772, 0.87341772, 0.83544304,\n",
            "       0.88607595, 0.86075949, 0.88607595, 0.91139241, 0.88607595,\n",
            "       0.86075949, 0.89873418, 0.92405063, 0.87341772, 0.91139241,\n",
            "       0.91139241, 0.91139241, 0.84810127, 0.89873418, 0.89873418,\n",
            "       0.89873418, 0.91139241, 0.96202532, 0.87341772, 0.89873418,\n",
            "       0.87341772, 0.91139241, 0.87341772, 0.89873418, 0.88607595,\n",
            "       0.87341772, 0.88607595, 0.94936709, 0.89873418, 0.89873418,\n",
            "       0.87341772, 0.86075949, 0.88607595, 0.88607595, 0.88607595,\n",
            "       0.88607595, 0.86075949, 0.88607595, 0.86075949, 0.87341772,\n",
            "       0.86075949, 0.89873418, 0.87341772, 0.87341772, 0.87341772,\n",
            "       0.91139241, 0.87341772, 0.86075949, 0.84810127, 0.92405063,\n",
            "       0.86075949, 0.89873418, 0.87341772, 0.91139241, 0.86075949,\n",
            "       0.86075949, 0.83544304, 0.91139241, 0.84810127, 0.88607595,\n",
            "       0.84810127, 0.82278481, 0.86075949, 0.87341772, 0.84810127,\n",
            "       0.84810127, 0.84810127, 0.84810127, 0.84810127, 0.87341772,\n",
            "       0.84810127, 0.86075949, 0.86075949, 0.92405063, 0.86075949,\n",
            "       0.86075949, 0.86075949, 0.87341772, 0.86075949, 0.92405063,\n",
            "       0.84810127, 0.94936709, 0.86075949, 0.88607595, 0.83544304,\n",
            "       0.91139241, 0.84810127, 0.88607595, 0.84810127, 0.92405063,\n",
            "       0.87341772, 0.92405063, 0.87341772, 0.94936709, 0.87341772,\n",
            "       0.92405063, 0.87341772, 0.89873418, 0.87341772, 0.89873418,\n",
            "       0.84810127, 0.92405063, 0.83544304, 0.86075949, 0.87341772,\n",
            "       0.86075949, 0.84810127, 0.84810127, 0.86075949, 0.91139241,\n",
            "       0.86075949, 0.92405063, 0.84810127, 0.93670886, 0.83544304,\n",
            "       0.91139241, 0.83544304, 0.91139241, 0.87341772, 0.87341772,\n",
            "       0.84810127, 0.87341772, 0.86075949, 0.94936709, 0.86075949,\n",
            "       0.86075949, 0.86075949, 0.89873418, 0.84810127, 0.92405063,\n",
            "       0.84810127, 0.91139241, 0.86075949, 0.84810127, 0.86075949,\n",
            "       0.84810127, 0.84810127, 0.89873418, 0.84810127, 0.93670886,\n",
            "       0.84810127, 0.88607595, 0.84810127, 0.93670886, 0.86075949,\n",
            "       0.87341772, 0.86075949, 0.84810127, 0.86075949, 0.88607595,\n",
            "       0.86075949, 0.87341772, 0.84810127, 0.86075949, 0.86075949,\n",
            "       0.88607595, 0.83544304, 0.92405063, 0.83544304, 0.87341772,\n",
            "       0.84810127, 0.89873418, 0.87341772, 0.88607595, 0.87341772,\n",
            "       0.89873418, 0.87341772, 0.89873418, 0.87341772, 0.87341772,\n",
            "       0.84810127, 0.93670886, 0.86075949, 0.93670886, 0.86075949,\n",
            "       0.88607595, 0.83544304, 0.87341772, 0.84810127, 0.92405063,\n",
            "       0.86075949, 0.89873418, 0.84810127, 0.91139241, 0.86075949,\n",
            "       0.89873418]), 'split7_test_score': array([0.86075949, 0.79746835, 0.86075949, 0.7721519 , 0.81012658,\n",
            "       0.82278481, 0.81012658, 0.81012658, 0.79746835, 0.73417722,\n",
            "       0.7721519 , 0.7721519 , 0.84810127, 0.81012658, 0.84810127,\n",
            "       0.78481013, 0.84810127, 0.78481013, 0.79746835, 0.7721519 ,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.78481013, 0.79746835,\n",
            "       0.73417722, 0.79746835, 0.78481013, 0.79746835, 0.7721519 ,\n",
            "       0.79746835, 0.78481013, 0.79746835, 0.75949367, 0.79746835,\n",
            "       0.79746835, 0.83544304, 0.78481013, 0.83544304, 0.78481013,\n",
            "       0.81012658, 0.84810127, 0.82278481, 0.74683544, 0.82278481,\n",
            "       0.84810127, 0.83544304, 0.84810127, 0.86075949, 0.74683544,\n",
            "       0.86075949, 0.79746835, 0.86075949, 0.82278481, 0.87341772,\n",
            "       0.86075949, 0.87341772, 0.83544304, 0.81012658, 0.81012658,\n",
            "       0.81012658, 0.79746835, 0.79746835, 0.86075949, 0.7721519 ,\n",
            "       0.82278481, 0.84810127, 0.82278481, 0.84810127, 0.79746835,\n",
            "       0.84810127, 0.83544304, 0.83544304, 0.84810127, 0.86075949,\n",
            "       0.82278481, 0.82278481, 0.81012658, 0.83544304, 0.79746835,\n",
            "       0.83544304, 0.81012658, 0.83544304, 0.81012658, 0.83544304,\n",
            "       0.7721519 , 0.84810127, 0.83544304, 0.83544304, 0.7721519 ,\n",
            "       0.83544304, 0.79746835, 0.83544304, 0.79746835, 0.83544304,\n",
            "       0.81012658, 0.83544304, 0.79746835, 0.83544304, 0.7721519 ,\n",
            "       0.83544304, 0.79746835, 0.83544304, 0.74683544, 0.83544304,\n",
            "       0.78481013, 0.83544304, 0.7721519 , 0.83544304, 0.78481013,\n",
            "       0.84810127, 0.75949367, 0.83544304, 0.81012658, 0.84810127,\n",
            "       0.83544304, 0.84810127, 0.79746835, 0.86075949, 0.7721519 ,\n",
            "       0.88607595, 0.79746835, 0.88607595, 0.82278481, 0.86075949,\n",
            "       0.7721519 , 0.83544304, 0.87341772, 0.84810127, 0.81012658,\n",
            "       0.81012658, 0.78481013, 0.86075949, 0.82278481, 0.84810127,\n",
            "       0.79746835, 0.83544304, 0.7721519 , 0.84810127, 0.78481013,\n",
            "       0.84810127, 0.81012658, 0.83544304, 0.78481013, 0.83544304,\n",
            "       0.82278481, 0.84810127, 0.75949367, 0.79746835, 0.82278481,\n",
            "       0.86075949, 0.86075949, 0.84810127, 0.75949367, 0.83544304,\n",
            "       0.75949367, 0.84810127, 0.79746835, 0.84810127, 0.84810127,\n",
            "       0.82278481, 0.7721519 , 0.83544304, 0.78481013, 0.83544304,\n",
            "       0.7721519 , 0.83544304, 0.79746835, 0.83544304, 0.81012658,\n",
            "       0.83544304, 0.78481013, 0.83544304, 0.78481013, 0.83544304,\n",
            "       0.78481013, 0.83544304, 0.78481013, 0.83544304, 0.79746835,\n",
            "       0.82278481, 0.81012658, 0.82278481, 0.82278481, 0.83544304,\n",
            "       0.81012658, 0.84810127, 0.78481013, 0.84810127, 0.79746835,\n",
            "       0.86075949, 0.83544304, 0.88607595, 0.75949367, 0.87341772,\n",
            "       0.78481013, 0.86075949, 0.78481013, 0.82278481, 0.82278481,\n",
            "       0.84810127, 0.86075949, 0.81012658, 0.83544304, 0.87341772,\n",
            "       0.81012658, 0.86075949, 0.78481013, 0.82278481, 0.82278481,\n",
            "       0.84810127, 0.79746835, 0.84810127, 0.83544304, 0.83544304,\n",
            "       0.78481013]), 'split8_test_score': array([0.89873418, 0.83544304, 0.88607595, 0.84810127, 0.84810127,\n",
            "       0.87341772, 0.87341772, 0.87341772, 0.87341772, 0.83544304,\n",
            "       0.83544304, 0.87341772, 0.81012658, 0.82278481, 0.81012658,\n",
            "       0.81012658, 0.81012658, 0.87341772, 0.7721519 , 0.81012658,\n",
            "       0.7721519 , 0.74683544, 0.7721519 , 0.81012658, 0.7721519 ,\n",
            "       0.86075949, 0.7721519 , 0.82278481, 0.7721519 , 0.79746835,\n",
            "       0.79746835, 0.75949367, 0.79746835, 0.87341772, 0.7721519 ,\n",
            "       0.82278481, 0.86075949, 0.81012658, 0.86075949, 0.79746835,\n",
            "       0.86075949, 0.86075949, 0.86075949, 0.87341772, 0.86075949,\n",
            "       0.81012658, 0.86075949, 0.84810127, 0.84810127, 0.86075949,\n",
            "       0.84810127, 0.88607595, 0.83544304, 0.81012658, 0.89873418,\n",
            "       0.81012658, 0.88607595, 0.83544304, 0.86075949, 0.84810127,\n",
            "       0.87341772, 0.88607595, 0.87341772, 0.86075949, 0.83544304,\n",
            "       0.79746835, 0.82278481, 0.87341772, 0.82278481, 0.82278481,\n",
            "       0.81012658, 0.82278481, 0.84810127, 0.92405063, 0.86075949,\n",
            "       0.82278481, 0.86075949, 0.84810127, 0.86075949, 0.83544304,\n",
            "       0.86075949, 0.81012658, 0.86075949, 0.87341772, 0.84810127,\n",
            "       0.83544304, 0.84810127, 0.86075949, 0.84810127, 0.79746835,\n",
            "       0.74683544, 0.83544304, 0.74683544, 0.81012658, 0.74683544,\n",
            "       0.7721519 , 0.74683544, 0.81012658, 0.74683544, 0.81012658,\n",
            "       0.74683544, 0.82278481, 0.7721519 , 0.84810127, 0.7721519 ,\n",
            "       0.84810127, 0.74683544, 0.78481013, 0.81012658, 0.79746835,\n",
            "       0.81012658, 0.86075949, 0.78481013, 0.83544304, 0.78481013,\n",
            "       0.82278481, 0.79746835, 0.82278481, 0.78481013, 0.84810127,\n",
            "       0.84810127, 0.86075949, 0.84810127, 0.82278481, 0.83544304,\n",
            "       0.82278481, 0.87341772, 0.82278481, 0.86075949, 0.86075949,\n",
            "       0.86075949, 0.73417722, 0.84810127, 0.84810127, 0.86075949,\n",
            "       0.87341772, 0.86075949, 0.82278481, 0.84810127, 0.84810127,\n",
            "       0.84810127, 0.83544304, 0.84810127, 0.83544304, 0.87341772,\n",
            "       0.88607595, 0.86075949, 0.88607595, 0.86075949, 0.82278481,\n",
            "       0.86075949, 0.89873418, 0.86075949, 0.83544304, 0.86075949,\n",
            "       0.82278481, 0.84810127, 0.81012658, 0.84810127, 0.79746835,\n",
            "       0.84810127, 0.88607595, 0.74683544, 0.82278481, 0.74683544,\n",
            "       0.79746835, 0.74683544, 0.83544304, 0.74683544, 0.73417722,\n",
            "       0.74683544, 0.82278481, 0.74683544, 0.84810127, 0.7721519 ,\n",
            "       0.82278481, 0.7721519 , 0.7721519 , 0.74683544, 0.7721519 ,\n",
            "       0.81012658, 0.82278481, 0.81012658, 0.82278481, 0.78481013,\n",
            "       0.87341772, 0.78481013, 0.86075949, 0.79746835, 0.83544304,\n",
            "       0.78481013, 0.87341772, 0.84810127, 0.81012658, 0.84810127,\n",
            "       0.83544304, 0.83544304, 0.81012658, 0.88607595, 0.83544304,\n",
            "       0.84810127, 0.81012658, 0.84810127, 0.81012658, 0.84810127,\n",
            "       0.86075949, 0.86075949, 0.84810127, 0.86075949, 0.82278481,\n",
            "       0.84810127, 0.86075949, 0.84810127, 0.82278481, 0.84810127,\n",
            "       0.84810127]), 'split9_test_score': array([0.78481013, 0.81012658, 0.7721519 , 0.81012658, 0.75949367,\n",
            "       0.82278481, 0.75949367, 0.87341772, 0.74683544, 0.82278481,\n",
            "       0.74683544, 0.79746835, 0.79746835, 0.82278481, 0.79746835,\n",
            "       0.81012658, 0.79746835, 0.82278481, 0.78481013, 0.73417722,\n",
            "       0.78481013, 0.7721519 , 0.75949367, 0.83544304, 0.78481013,\n",
            "       0.7721519 , 0.78481013, 0.84810127, 0.75949367, 0.84810127,\n",
            "       0.75949367, 0.83544304, 0.75949367, 0.7721519 , 0.75949367,\n",
            "       0.78481013, 0.81012658, 0.86075949, 0.79746835, 0.83544304,\n",
            "       0.7721519 , 0.78481013, 0.7721519 , 0.75949367, 0.7721519 ,\n",
            "       0.86075949, 0.75949367, 0.81012658, 0.79746835, 0.78481013,\n",
            "       0.79746835, 0.89873418, 0.79746835, 0.81012658, 0.7721519 ,\n",
            "       0.81012658, 0.7721519 , 0.81012658, 0.7721519 , 0.88607595,\n",
            "       0.74683544, 0.81012658, 0.74683544, 0.78481013, 0.74683544,\n",
            "       0.79746835, 0.79746835, 0.83544304, 0.79746835, 0.83544304,\n",
            "       0.79746835, 0.79746835, 0.72151899, 0.78481013, 0.72151899,\n",
            "       0.83544304, 0.79746835, 0.75949367, 0.69620253, 0.87341772,\n",
            "       0.69620253, 0.84810127, 0.7721519 , 0.83544304, 0.79746835,\n",
            "       0.78481013, 0.79746835, 0.82278481, 0.79746835, 0.84810127,\n",
            "       0.7721519 , 0.81012658, 0.7721519 , 0.82278481, 0.7721519 ,\n",
            "       0.79746835, 0.7721519 , 0.79746835, 0.7721519 , 0.81012658,\n",
            "       0.7721519 , 0.79746835, 0.7721519 , 0.7721519 , 0.7721519 ,\n",
            "       0.83544304, 0.7721519 , 0.7721519 , 0.81012658, 0.79746835,\n",
            "       0.7721519 , 0.81012658, 0.7721519 , 0.79746835, 0.69620253,\n",
            "       0.83544304, 0.69620253, 0.79746835, 0.7721519 , 0.83544304,\n",
            "       0.78481013, 0.78481013, 0.78481013, 0.72151899, 0.78481013,\n",
            "       0.79746835, 0.75949367, 0.82278481, 0.72151899, 0.82278481,\n",
            "       0.79746835, 0.82278481, 0.69620253, 0.79746835, 0.69620253,\n",
            "       0.81012658, 0.7721519 , 0.81012658, 0.79746835, 0.74683544,\n",
            "       0.79746835, 0.75949367, 0.79746835, 0.79746835, 0.78481013,\n",
            "       0.79746835, 0.74683544, 0.84810127, 0.79746835, 0.83544304,\n",
            "       0.69620253, 0.84810127, 0.69620253, 0.7721519 , 0.7721519 ,\n",
            "       0.79746835, 0.79746835, 0.84810127, 0.79746835, 0.86075949,\n",
            "       0.79746835, 0.83544304, 0.7721519 , 0.78481013, 0.7721519 ,\n",
            "       0.78481013, 0.7721519 , 0.83544304, 0.7721519 , 0.81012658,\n",
            "       0.7721519 , 0.82278481, 0.7721519 , 0.81012658, 0.7721519 ,\n",
            "       0.75949367, 0.7721519 , 0.81012658, 0.7721519 , 0.78481013,\n",
            "       0.7721519 , 0.79746835, 0.72151899, 0.84810127, 0.7721519 ,\n",
            "       0.7721519 , 0.69620253, 0.82278481, 0.73417722, 0.79746835,\n",
            "       0.74683544, 0.86075949, 0.78481013, 0.78481013, 0.78481013,\n",
            "       0.86075949, 0.78481013, 0.75949367, 0.73417722, 0.82278481,\n",
            "       0.78481013, 0.75949367, 0.79746835, 0.86075949, 0.69620253,\n",
            "       0.81012658, 0.70886076, 0.82278481, 0.7721519 , 0.82278481,\n",
            "       0.79746835, 0.81012658, 0.79746835, 0.82278481, 0.79746835,\n",
            "       0.79746835]), 'mean_test_score': array([0.80375   , 0.80860759, 0.80620253, 0.8035443 , 0.80237342,\n",
            "       0.80240506, 0.79609177, 0.80246835, 0.79985759, 0.79977848,\n",
            "       0.78849684, 0.81745253, 0.80234177, 0.79863924, 0.80107595,\n",
            "       0.79101266, 0.80231013, 0.80488924, 0.77968354, 0.7796519 ,\n",
            "       0.78219937, 0.7759019 , 0.78093354, 0.79857595, 0.78219937,\n",
            "       0.7884019 , 0.78219937, 0.78599684, 0.77966772, 0.77966772,\n",
            "       0.78471519, 0.79468354, 0.78471519, 0.79863924, 0.78218354,\n",
            "       0.78088608, 0.81129747, 0.81737342, 0.80998418, 0.82360759,\n",
            "       0.80618671, 0.80488924, 0.81117089, 0.81226266, 0.81117089,\n",
            "       0.81995253, 0.80868671, 0.82245253, 0.81623418, 0.78846519,\n",
            "       0.81243671, 0.81876582, 0.81370253, 0.79852848, 0.80757911,\n",
            "       0.81237342, 0.81254747, 0.82003165, 0.80362342, 0.81368671,\n",
            "       0.79859177, 0.79360759, 0.80110759, 0.82379747, 0.79101266,\n",
            "       0.7985443 , 0.80235759, 0.80985759, 0.80363924, 0.80474684,\n",
            "       0.80232595, 0.80099684, 0.79609177, 0.81243671, 0.80615506,\n",
            "       0.81375   , 0.80245253, 0.79602848, 0.7960443 , 0.81745253,\n",
            "       0.79356013, 0.81359177, 0.79992089, 0.80493671, 0.80112342,\n",
            "       0.79094937, 0.80109177, 0.81240506, 0.80362342, 0.80359177,\n",
            "       0.79094937, 0.79223101, 0.79348101, 0.78973101, 0.79221519,\n",
            "       0.76837025, 0.78843354, 0.79591772, 0.78843354, 0.78837025,\n",
            "       0.78843354, 0.79593354, 0.79601266, 0.7860443 , 0.79601266,\n",
            "       0.78849684, 0.79348101, 0.76707278, 0.79235759, 0.81109177,\n",
            "       0.78602848, 0.80862342, 0.78606013, 0.81488924, 0.77338608,\n",
            "       0.81615506, 0.77844937, 0.8097943 , 0.78731013, 0.81232595,\n",
            "       0.80113924, 0.80232595, 0.79863924, 0.80731013, 0.80365506,\n",
            "       0.79844937, 0.80365506, 0.82492089, 0.80109177, 0.82246835,\n",
            "       0.80245253, 0.79341772, 0.79476266, 0.80363924, 0.79982595,\n",
            "       0.80860759, 0.80368671, 0.79599684, 0.80238924, 0.79849684,\n",
            "       0.80113924, 0.80363924, 0.80363924, 0.80110759, 0.79609177,\n",
            "       0.81248418, 0.80234177, 0.81357595, 0.80118671, 0.7960443 ,\n",
            "       0.79859177, 0.82632911, 0.79231013, 0.80102848, 0.79865506,\n",
            "       0.7959019 , 0.80112342, 0.7985443 , 0.80237342, 0.81120253,\n",
            "       0.80237342, 0.81238924, 0.79348101, 0.78843354, 0.79348101,\n",
            "       0.77713608, 0.79221519, 0.80243671, 0.78843354, 0.77093354,\n",
            "       0.78843354, 0.78093354, 0.78843354, 0.79988924, 0.79601266,\n",
            "       0.78091772, 0.79601266, 0.79593354, 0.79348101, 0.79976266,\n",
            "       0.78227848, 0.81112342, 0.7746519 , 0.81613924, 0.78732595,\n",
            "       0.8072943 , 0.77338608, 0.81118671, 0.78096519, 0.79973101,\n",
            "       0.78099684, 0.82375   , 0.80240506, 0.78713608, 0.80367089,\n",
            "       0.81610759, 0.79735759, 0.79094937, 0.79237342, 0.8097943 ,\n",
            "       0.80365506, 0.80613924, 0.80243671, 0.81870253, 0.79357595,\n",
            "       0.80860759, 0.7985443 , 0.81860759, 0.79867089, 0.80860759,\n",
            "       0.80363924, 0.79981013, 0.80363924, 0.81990506, 0.80490506,\n",
            "       0.81101266]), 'std_test_score': array([0.05988355, 0.04659907, 0.04852365, 0.03897677, 0.04844047,\n",
            "       0.05557235, 0.0454677 , 0.06913247, 0.04721358, 0.04801589,\n",
            "       0.05180908, 0.05284829, 0.0438786 , 0.05299547, 0.04455258,\n",
            "       0.04730414, 0.04263888, 0.04646268, 0.04026612, 0.042722  ,\n",
            "       0.0369258 , 0.0411803 , 0.04073992, 0.03470453, 0.03938292,\n",
            "       0.06344744, 0.03938292, 0.0557376 , 0.03994344, 0.03670247,\n",
            "       0.04119599, 0.04348798, 0.04119599, 0.05264691, 0.04111228,\n",
            "       0.04368349, 0.04849668, 0.0467592 , 0.03956572, 0.03907964,\n",
            "       0.05176505, 0.05179445, 0.03808194, 0.05188895, 0.04778529,\n",
            "       0.0476204 , 0.05499639, 0.06141628, 0.04789362, 0.05532377,\n",
            "       0.04877101, 0.0591515 , 0.04371805, 0.04466977, 0.06455046,\n",
            "       0.04285965, 0.0534123 , 0.04709947, 0.04785101, 0.06342874,\n",
            "       0.04772481, 0.0451894 , 0.04802125, 0.03320141, 0.04814454,\n",
            "       0.04150548, 0.04381829, 0.05412891, 0.04549528, 0.04936582,\n",
            "       0.03987549, 0.06041773, 0.04922402, 0.05431818, 0.04783484,\n",
            "       0.04063847, 0.04520784, 0.03944144, 0.04584421, 0.05457884,\n",
            "       0.04787265, 0.04300792, 0.04780489, 0.05063641, 0.03870458,\n",
            "       0.03864025, 0.03720673, 0.05198199, 0.03509132, 0.04156354,\n",
            "       0.03293069, 0.04582615, 0.03380939, 0.04518852, 0.03141927,\n",
            "       0.03810943, 0.03411118, 0.03361035, 0.03411118, 0.04738422,\n",
            "       0.03411118, 0.04117076, 0.03204806, 0.05998279, 0.03204806,\n",
            "       0.0484109 , 0.03472139, 0.05879933, 0.04205552, 0.05364468,\n",
            "       0.04105499, 0.05687402, 0.04555272, 0.0327363 , 0.04839997,\n",
            "       0.04263167, 0.05028663, 0.03563033, 0.04842624, 0.0611597 ,\n",
            "       0.05827228, 0.05250953, 0.0588014 , 0.06160559, 0.05042612,\n",
            "       0.05693999, 0.04630021, 0.04504123, 0.04714146, 0.04527772,\n",
            "       0.04154126, 0.05586685, 0.04638098, 0.0380108 , 0.05037372,\n",
            "       0.04258394, 0.04285639, 0.03309778, 0.04038069, 0.06191406,\n",
            "       0.0421383 , 0.05705723, 0.0340878 , 0.05427861, 0.04330168,\n",
            "       0.04779908, 0.03702422, 0.06852365, 0.04479616, 0.0499998 ,\n",
            "       0.04882771, 0.04718206, 0.04980399, 0.06074018, 0.04597456,\n",
            "       0.04732481, 0.04111352, 0.049934  , 0.03883944, 0.05454285,\n",
            "       0.0335728 , 0.05357568, 0.03380939, 0.04474092, 0.03380939,\n",
            "       0.03737952, 0.03141927, 0.04432658, 0.03411118, 0.06333571,\n",
            "       0.03411118, 0.05503606, 0.03411118, 0.06059805, 0.03204806,\n",
            "       0.04278033, 0.03204806, 0.04068198, 0.03472139, 0.03666841,\n",
            "       0.04693941, 0.03658897, 0.04259862, 0.02881928, 0.04802758,\n",
            "       0.05296108, 0.04839997, 0.04749077, 0.04199494, 0.04289125,\n",
            "       0.04975427, 0.04382457, 0.05609639, 0.04683374, 0.05226976,\n",
            "       0.04637155, 0.05180487, 0.05249578, 0.0548953 , 0.04186408,\n",
            "       0.03214405, 0.05243466, 0.04121799, 0.05600697, 0.05343826,\n",
            "       0.04627975, 0.04495191, 0.03363049, 0.04412102, 0.04775301,\n",
            "       0.04309802, 0.04719148, 0.03884473, 0.04262964, 0.0359021 ,\n",
            "       0.04885758]), 'rank_test_score': array([ 66,  50,  57,  81,  90,  87, 134,  82, 113, 116, 172,  14,  94,\n",
            "       122, 108, 166,  98,  63, 204, 207, 194, 210, 200, 126, 194, 182,\n",
            "       194, 190, 205, 205, 191, 150, 191, 122, 197, 203,  36,  16,  44,\n",
            "         5,  58,  63,  39,  35,  39,   9,  48,   7,  17, 174,  29,  11,\n",
            "        23, 130,  54,  33,  27,   8,  78,  24, 124, 151, 104,   3, 166,\n",
            "       128,  93,  45,  72,  65,  96, 110, 134,  29,  59,  22,  83, 139,\n",
            "       137,  14, 153,  25, 111,  61, 102, 169, 106,  31,  78,  80, 168,\n",
            "       163, 154, 171, 164, 215, 175, 147, 175, 183, 175, 145, 140, 188,\n",
            "       140, 172, 154, 216, 161,  42, 189,  49, 187,  21, 212,  18, 208,\n",
            "        46, 185,  34, 100,  96, 121,  55,  69, 132,  69,   2, 106,   6,\n",
            "        83, 159, 149,  72, 114,  50,  67, 144,  89, 131, 101,  72,  72,\n",
            "       104, 134,  28,  94,  26,  99, 137, 124,   1, 162, 109, 120, 148,\n",
            "       102, 128,  90,  37,  90,  32, 154, 181, 154, 209, 164,  85, 175,\n",
            "       214, 175, 200, 175, 112, 140, 202, 140, 145, 154, 117, 193,  41,\n",
            "       211,  19, 184,  56, 212,  38, 199, 118, 198,   4,  88, 186,  68,\n",
            "        20, 133, 169, 160,  46,  69,  60,  86,  12, 152,  50, 127,  13,\n",
            "       119,  50,  72, 115,  72,  10,  62,  43], dtype=int32), 'split0_train_score': array([0.99439776, 0.99439776, 0.96638655, 0.94817927, 0.93137255,\n",
            "       0.90896359, 0.93837535, 0.90056022, 0.93837535, 0.89495798,\n",
            "       0.91316527, 0.88095238, 0.90336134, 0.8697479 , 0.9047619 ,\n",
            "       0.87535014, 0.89635854, 0.86134454, 0.85434174, 0.81372549,\n",
            "       0.85294118, 0.82212885, 0.85154062, 0.83753501, 0.85014006,\n",
            "       0.84033613, 0.85014006, 0.80952381, 0.85014006, 0.83893557,\n",
            "       0.85294118, 0.83473389, 0.85294118, 0.84173669, 0.85014006,\n",
            "       0.82773109, 0.94677871, 0.92156863, 0.93697479, 0.89495798,\n",
            "       0.91456583, 0.88515406, 0.92717087, 0.88935574, 0.92717087,\n",
            "       0.89495798, 0.90896359, 0.87114846, 0.90056022, 0.85154062,\n",
            "       0.89915966, 0.85014006, 0.89215686, 0.86134454, 0.9789916 ,\n",
            "       0.96218487, 0.95518207, 0.93137255, 0.92717087, 0.90896359,\n",
            "       0.93557423, 0.89215686, 0.93557423, 0.90616246, 0.91316527,\n",
            "       0.88515406, 0.9047619 , 0.86554622, 0.9047619 , 0.86834734,\n",
            "       0.89495798, 0.8557423 , 0.99439776, 0.99439776, 0.97478992,\n",
            "       0.95658263, 0.95098039, 0.91596639, 0.94957983, 0.91456583,\n",
            "       0.94957983, 0.89215686, 0.93417367, 0.88655462, 0.9047619 ,\n",
            "       0.85714286, 0.9047619 , 0.8557423 , 0.90196078, 0.85434174,\n",
            "       0.84173669, 0.83613445, 0.84033613, 0.82352941, 0.84033613,\n",
            "       0.83193277, 0.83893557, 0.85154062, 0.83893557, 0.83333333,\n",
            "       0.83893557, 0.81792717, 0.83473389, 0.83753501, 0.83473389,\n",
            "       0.82633053, 0.83473389, 0.81092437, 0.92296919, 0.90056022,\n",
            "       0.91596639, 0.90756303, 0.90616246, 0.89215686, 0.90616246,\n",
            "       0.88235294, 0.90616246, 0.88095238, 0.8977591 , 0.86694678,\n",
            "       0.88655462, 0.8627451 , 0.88655462, 0.85014006, 0.8837535 ,\n",
            "       0.85854342, 0.9859944 , 0.96218487, 0.96638655, 0.92717087,\n",
            "       0.94817927, 0.8977591 , 0.94677871, 0.90616246, 0.94677871,\n",
            "       0.89355742, 0.93417367, 0.88795518, 0.9047619 , 0.85714286,\n",
            "       0.9047619 , 0.85434174, 0.90196078, 0.87535014, 0.99439776,\n",
            "       0.99439776, 0.9719888 , 0.93977591, 0.94817927, 0.9047619 ,\n",
            "       0.94957983, 0.90616246, 0.94957983, 0.88655462, 0.93417367,\n",
            "       0.87535014, 0.9047619 , 0.85854342, 0.9047619 , 0.86134454,\n",
            "       0.90196078, 0.8557423 , 0.84173669, 0.81932773, 0.84033613,\n",
            "       0.83473389, 0.84033613, 0.83893557, 0.83893557, 0.82492997,\n",
            "       0.83893557, 0.83893557, 0.83893557, 0.83473389, 0.83473389,\n",
            "       0.84173669, 0.83473389, 0.83753501, 0.83473389, 0.83053221,\n",
            "       0.92296919, 0.92156863, 0.91596639, 0.90756303, 0.90616246,\n",
            "       0.8977591 , 0.90616246, 0.88515406, 0.90616246, 0.87955182,\n",
            "       0.8977591 , 0.87254902, 0.88655462, 0.85714286, 0.88655462,\n",
            "       0.86414566, 0.8837535 , 0.84453782, 0.9859944 , 0.95798319,\n",
            "       0.97058824, 0.93417367, 0.94817927, 0.89495798, 0.94677871,\n",
            "       0.90616246, 0.94677871, 0.90056022, 0.93417367, 0.87815126,\n",
            "       0.9047619 , 0.8557423 , 0.9047619 , 0.86134454, 0.90196078,\n",
            "       0.8487395 ]), 'split1_train_score': array([0.99439776, 0.99439776, 0.96078431, 0.94537815, 0.94257703,\n",
            "       0.91876751, 0.93277311, 0.89635854, 0.92997199, 0.88655462,\n",
            "       0.91316527, 0.87955182, 0.90056022, 0.85014006, 0.90056022,\n",
            "       0.85434174, 0.89915966, 0.85854342, 0.85014006, 0.82212885,\n",
            "       0.8487395 , 0.82072829, 0.8487395 , 0.82913165, 0.84453782,\n",
            "       0.83053221, 0.84453782, 0.81372549, 0.84453782, 0.81372549,\n",
            "       0.84173669, 0.82352941, 0.84173669, 0.82072829, 0.84173669,\n",
            "       0.80812325, 0.95378151, 0.92296919, 0.93977591, 0.91596639,\n",
            "       0.92857143, 0.90056022, 0.91736695, 0.89355742, 0.91736695,\n",
            "       0.88515406, 0.91036415, 0.8767507 , 0.89915966, 0.84593838,\n",
            "       0.89915966, 0.8557423 , 0.89635854, 0.85154062, 0.98039216,\n",
            "       0.9719888 , 0.95378151, 0.93977591, 0.93557423, 0.91036415,\n",
            "       0.93277311, 0.89495798, 0.92997199, 0.88515406, 0.91456583,\n",
            "       0.87535014, 0.90056022, 0.86414566, 0.90056022, 0.84733894,\n",
            "       0.8977591 , 0.83893557, 0.99439776, 0.99439776, 0.96638655,\n",
            "       0.95098039, 0.92717087, 0.92156863, 0.94677871, 0.8977591 ,\n",
            "       0.94537815, 0.8907563 , 0.92016807, 0.8697479 , 0.90196078,\n",
            "       0.8557423 , 0.90196078, 0.85714286, 0.89495798, 0.84173669,\n",
            "       0.84173669, 0.81232493, 0.84033613, 0.84173669, 0.84033613,\n",
            "       0.80952381, 0.83893557, 0.82212885, 0.83893557, 0.81652661,\n",
            "       0.83893557, 0.82072829, 0.83473389, 0.82212885, 0.83473389,\n",
            "       0.81652661, 0.83473389, 0.81232493, 0.92156863, 0.91596639,\n",
            "       0.91036415, 0.88795518, 0.8977591 , 0.88235294, 0.90056022,\n",
            "       0.88235294, 0.90196078, 0.87815126, 0.89355742, 0.8767507 ,\n",
            "       0.89635854, 0.85714286, 0.89635854, 0.84453782, 0.89215686,\n",
            "       0.84173669, 0.9719888 , 0.98319328, 0.95238095, 0.93557423,\n",
            "       0.92436975, 0.89915966, 0.93697479, 0.89215686, 0.93697479,\n",
            "       0.87815126, 0.91736695, 0.86694678, 0.89915966, 0.86554622,\n",
            "       0.89915966, 0.86834734, 0.89495798, 0.85434174, 0.99439776,\n",
            "       0.99439776, 0.96638655, 0.94957983, 0.93137255, 0.90896359,\n",
            "       0.94677871, 0.9047619 , 0.94677871, 0.89495798, 0.92156863,\n",
            "       0.87955182, 0.90196078, 0.8627451 , 0.90196078, 0.86834734,\n",
            "       0.89495798, 0.8627451 , 0.84173669, 0.82352941, 0.84033613,\n",
            "       0.81512605, 0.84033613, 0.80532213, 0.83893557, 0.81092437,\n",
            "       0.83893557, 0.80392157, 0.83893557, 0.81792717, 0.83473389,\n",
            "       0.80392157, 0.83473389, 0.82773109, 0.83473389, 0.81792717,\n",
            "       0.92016807, 0.91736695, 0.91036415, 0.91596639, 0.89915966,\n",
            "       0.88795518, 0.90196078, 0.89635854, 0.90056022, 0.87254902,\n",
            "       0.89355742, 0.85294118, 0.89635854, 0.87254902, 0.89635854,\n",
            "       0.86694678, 0.89215686, 0.8487395 , 0.97478992, 0.96078431,\n",
            "       0.94957983, 0.93417367, 0.92436975, 0.91316527, 0.93837535,\n",
            "       0.8907563 , 0.93697479, 0.89355742, 0.91736695, 0.8907563 ,\n",
            "       0.89915966, 0.85854342, 0.89915966, 0.86834734, 0.89495798,\n",
            "       0.86134454]), 'split2_train_score': array([0.99579832, 0.99579832, 0.96918768, 0.94537815, 0.94397759,\n",
            "       0.92577031, 0.94537815, 0.90756303, 0.93977591, 0.89495798,\n",
            "       0.91456583, 0.87955182, 0.90336134, 0.85294118, 0.90056022,\n",
            "       0.85714286, 0.89915966, 0.85714286, 0.86134454, 0.82072829,\n",
            "       0.86134454, 0.83333333, 0.86134454, 0.80112045, 0.8557423 ,\n",
            "       0.83473389, 0.8557423 , 0.84313725, 0.8557423 , 0.83473389,\n",
            "       0.8557423 , 0.82913165, 0.8557423 , 0.83473389, 0.8557423 ,\n",
            "       0.81372549, 0.93837535, 0.89495798, 0.92857143, 0.88935574,\n",
            "       0.91736695, 0.90196078, 0.92857143, 0.89495798, 0.92296919,\n",
            "       0.88515406, 0.91036415, 0.87815126, 0.89915966, 0.85154062,\n",
            "       0.89915966, 0.84033613, 0.89215686, 0.8627451 , 0.98039216,\n",
            "       0.96918768, 0.95938375, 0.93557423, 0.94117647, 0.91736695,\n",
            "       0.94257703, 0.89635854, 0.93697479, 0.89635854, 0.91456583,\n",
            "       0.87114846, 0.90056022, 0.85714286, 0.90336134, 0.85714286,\n",
            "       0.89635854, 0.85294118, 0.99579832, 0.99579832, 0.96918768,\n",
            "       0.94817927, 0.93417367, 0.92577031, 0.94397759, 0.90336134,\n",
            "       0.93837535, 0.89495798, 0.91316527, 0.86834734, 0.90616246,\n",
            "       0.86554622, 0.9047619 , 0.85294118, 0.90196078, 0.85994398,\n",
            "       0.85154062, 0.83053221, 0.85154062, 0.82072829, 0.85014006,\n",
            "       0.83333333, 0.84733894, 0.80532213, 0.84733894, 0.82352941,\n",
            "       0.84733894, 0.82773109, 0.84733894, 0.83053221, 0.84733894,\n",
            "       0.83893557, 0.84733894, 0.84173669, 0.91316527, 0.91456583,\n",
            "       0.90896359, 0.8977591 , 0.89215686, 0.88795518, 0.90196078,\n",
            "       0.88795518, 0.89635854, 0.8697479 , 0.87955182, 0.8767507 ,\n",
            "       0.8907563 , 0.85294118, 0.88935574, 0.85854342, 0.88655462,\n",
            "       0.86554622, 0.9719888 , 0.95938375, 0.95378151, 0.94397759,\n",
            "       0.92577031, 0.90616246, 0.93137255, 0.89355742, 0.92577031,\n",
            "       0.89355742, 0.90756303, 0.88935574, 0.90336134, 0.86134454,\n",
            "       0.90336134, 0.85714286, 0.8977591 , 0.85294118, 0.99579832,\n",
            "       0.99579832, 0.96918768, 0.95518207, 0.93417367, 0.91456583,\n",
            "       0.94397759, 0.90196078, 0.93837535, 0.89215686, 0.91316527,\n",
            "       0.86834734, 0.90616246, 0.85294118, 0.90616246, 0.85994398,\n",
            "       0.90056022, 0.86554622, 0.85154062, 0.80812325, 0.85154062,\n",
            "       0.83613445, 0.85014006, 0.82352941, 0.84733894, 0.81092437,\n",
            "       0.84733894, 0.82212885, 0.84733894, 0.84033613, 0.84733894,\n",
            "       0.83053221, 0.84733894, 0.81372549, 0.84733894, 0.82633053,\n",
            "       0.91736695, 0.89495798, 0.90896359, 0.90196078, 0.88795518,\n",
            "       0.8907563 , 0.90196078, 0.89215686, 0.89635854, 0.89355742,\n",
            "       0.87955182, 0.86834734, 0.8907563 , 0.85434174, 0.8907563 ,\n",
            "       0.85714286, 0.88515406, 0.85434174, 0.9719888 , 0.95798319,\n",
            "       0.95238095, 0.92717087, 0.92436975, 0.90616246, 0.93137255,\n",
            "       0.89635854, 0.92577031, 0.90196078, 0.90756303, 0.8837535 ,\n",
            "       0.90196078, 0.84173669, 0.90336134, 0.85014006, 0.8977591 ,\n",
            "       0.86694678]), 'split3_train_score': array([0.99439776, 0.99439776, 0.96638655, 0.94117647, 0.92717087,\n",
            "       0.90896359, 0.93837535, 0.89215686, 0.93277311, 0.90756303,\n",
            "       0.9047619 , 0.88655462, 0.9047619 , 0.8557423 , 0.9047619 ,\n",
            "       0.8627451 , 0.89495798, 0.85434174, 0.85014006, 0.82633053,\n",
            "       0.84733894, 0.82913165, 0.84733894, 0.81792717, 0.84453782,\n",
            "       0.80812325, 0.84453782, 0.83193277, 0.84453782, 0.80392157,\n",
            "       0.84173669, 0.81932773, 0.84173669, 0.82072829, 0.84173669,\n",
            "       0.81232493, 0.95238095, 0.91456583, 0.93837535, 0.89635854,\n",
            "       0.91316527, 0.8837535 , 0.91316527, 0.86554622, 0.91036415,\n",
            "       0.87955182, 0.8977591 , 0.88655462, 0.89495798, 0.85434174,\n",
            "       0.89495798, 0.8557423 , 0.88655462, 0.85014006, 0.98319328,\n",
            "       0.93557423, 0.96078431, 0.92997199, 0.92296919, 0.89355742,\n",
            "       0.93837535, 0.89915966, 0.93277311, 0.90336134, 0.90756303,\n",
            "       0.87254902, 0.9047619 , 0.86414566, 0.9047619 , 0.85434174,\n",
            "       0.89495798, 0.85154062, 0.99439776, 0.99439776, 0.96498599,\n",
            "       0.95238095, 0.92997199, 0.91736695, 0.93977591, 0.90336134,\n",
            "       0.93977591, 0.91036415, 0.91736695, 0.86554622, 0.91316527,\n",
            "       0.84593838, 0.91316527, 0.8557423 , 0.90616246, 0.8487395 ,\n",
            "       0.83333333, 0.80532213, 0.83193277, 0.81932773, 0.83193277,\n",
            "       0.81512605, 0.83053221, 0.82633053, 0.83053221, 0.81232493,\n",
            "       0.83053221, 0.82913165, 0.83053221, 0.81092437, 0.83053221,\n",
            "       0.82212885, 0.83053221, 0.82633053, 0.95238095, 0.90056022,\n",
            "       0.93697479, 0.90336134, 0.91876751, 0.85994398, 0.91736695,\n",
            "       0.8697479 , 0.91736695, 0.87535014, 0.90756303, 0.86694678,\n",
            "       0.90616246, 0.84033613, 0.90616246, 0.85714286, 0.90336134,\n",
            "       0.85014006, 0.9929972 , 0.94537815, 0.96638655, 0.92857143,\n",
            "       0.93137255, 0.89495798, 0.93977591, 0.8907563 , 0.94117647,\n",
            "       0.90196078, 0.91736695, 0.8697479 , 0.91316527, 0.8627451 ,\n",
            "       0.91316527, 0.8557423 , 0.90616246, 0.85434174, 0.99439776,\n",
            "       0.99439776, 0.96498599, 0.95378151, 0.93137255, 0.90616246,\n",
            "       0.94117647, 0.90756303, 0.93977591, 0.89355742, 0.91736695,\n",
            "       0.88935574, 0.91316527, 0.85434174, 0.91316527, 0.85154062,\n",
            "       0.90616246, 0.85714286, 0.83333333, 0.83753501, 0.83193277,\n",
            "       0.83053221, 0.83193277, 0.80392157, 0.83053221, 0.81232493,\n",
            "       0.83053221, 0.82072829, 0.83053221, 0.81372549, 0.83053221,\n",
            "       0.82633053, 0.83053221, 0.83333333, 0.83053221, 0.82072829,\n",
            "       0.95238095, 0.8907563 , 0.93697479, 0.87114846, 0.92016807,\n",
            "       0.86694678, 0.91736695, 0.88515406, 0.91736695, 0.86414566,\n",
            "       0.90756303, 0.86834734, 0.90616246, 0.83893557, 0.90616246,\n",
            "       0.85154062, 0.90336134, 0.85294118, 0.9929972 , 0.96638655,\n",
            "       0.96638655, 0.92296919, 0.93137255, 0.90056022, 0.93977591,\n",
            "       0.91316527, 0.93837535, 0.90056022, 0.91736695, 0.86834734,\n",
            "       0.91316527, 0.8627451 , 0.91316527, 0.8697479 , 0.90616246,\n",
            "       0.8557423 ]), 'split4_train_score': array([0.99300699, 0.99300699, 0.96083916, 0.94405594, 0.93006993,\n",
            "       0.9034965 , 0.93706294, 0.8951049 , 0.93566434, 0.89230769,\n",
            "       0.90769231, 0.87692308, 0.9034965 , 0.85874126, 0.9034965 ,\n",
            "       0.87132867, 0.9006993 , 0.87272727, 0.85314685, 0.82797203,\n",
            "       0.85174825, 0.82657343, 0.85034965, 0.83636364, 0.84615385,\n",
            "       0.83076923, 0.84615385, 0.81118881, 0.84615385, 0.84475524,\n",
            "       0.84615385, 0.81958042, 0.84615385, 0.83076923, 0.84615385,\n",
            "       0.82937063, 0.95524476, 0.93426573, 0.93846154, 0.8993007 ,\n",
            "       0.91748252, 0.88951049, 0.92027972, 0.87972028, 0.91888112,\n",
            "       0.87552448, 0.8979021 , 0.87412587, 0.8951049 , 0.86993007,\n",
            "       0.8951049 , 0.86153846, 0.89230769, 0.85874126, 0.98181818,\n",
            "       0.95104895, 0.95384615, 0.93846154, 0.92867133, 0.89090909,\n",
            "       0.93006993, 0.89090909, 0.93146853, 0.89370629, 0.9034965 ,\n",
            "       0.86433566, 0.9006993 , 0.86573427, 0.9006993 , 0.85734266,\n",
            "       0.8979021 , 0.86433566, 0.99300699, 0.99300699, 0.96643357,\n",
            "       0.94965035, 0.93426573, 0.91608392, 0.94125874, 0.9048951 ,\n",
            "       0.94125874, 0.89090909, 0.91468531, 0.87132867, 0.90769231,\n",
            "       0.86853147, 0.90769231, 0.86713287, 0.9006993 , 0.85314685,\n",
            "       0.84055944, 0.83496503, 0.83916084, 0.80559441, 0.83776224,\n",
            "       0.82657343, 0.83496503, 0.80979021, 0.83496503, 0.82517483,\n",
            "       0.83496503, 0.82517483, 0.83496503, 0.80839161, 0.83496503,\n",
            "       0.80979021, 0.83496503, 0.82237762, 0.93146853, 0.9034965 ,\n",
            "       0.92307692, 0.90629371, 0.90769231, 0.88811189, 0.90909091,\n",
            "       0.88951049, 0.90909091, 0.88391608, 0.89370629, 0.87552448,\n",
            "       0.8951049 , 0.85874126, 0.8951049 , 0.84195804, 0.89230769,\n",
            "       0.86013986, 0.97762238, 0.97622378, 0.95524476, 0.93566434,\n",
            "       0.93006993, 0.8993007 , 0.93286713, 0.8965035 , 0.93146853,\n",
            "       0.89090909, 0.91048951, 0.87832168, 0.90769231, 0.87272727,\n",
            "       0.90769231, 0.86013986, 0.9006993 , 0.86573427, 0.99300699,\n",
            "       0.99300699, 0.96783217, 0.95104895, 0.93426573, 0.91888112,\n",
            "       0.93986014, 0.90769231, 0.94125874, 0.89370629, 0.91468531,\n",
            "       0.88251748, 0.90769231, 0.86293706, 0.90769231, 0.85874126,\n",
            "       0.9006993 , 0.85734266, 0.84055944, 0.82937063, 0.83916084,\n",
            "       0.83496503, 0.83776224, 0.83776224, 0.83496503, 0.82517483,\n",
            "       0.83496503, 0.82517483, 0.83496503, 0.82937063, 0.83496503,\n",
            "       0.83356643, 0.83496503, 0.84055944, 0.83496503, 0.84195804,\n",
            "       0.93286713, 0.92167832, 0.92307692, 0.90629371, 0.90909091,\n",
            "       0.86993007, 0.90909091, 0.87132867, 0.90769231, 0.88251748,\n",
            "       0.89370629, 0.85874126, 0.8951049 , 0.85314685, 0.8951049 ,\n",
            "       0.86293706, 0.89230769, 0.86153846, 0.98041958, 0.96643357,\n",
            "       0.95664336, 0.93426573, 0.92727273, 0.8979021 , 0.93426573,\n",
            "       0.8965035 , 0.93146853, 0.8965035 , 0.91048951, 0.88111888,\n",
            "       0.90769231, 0.86293706, 0.90769231, 0.85734266, 0.9006993 ,\n",
            "       0.84755245]), 'split5_train_score': array([0.99440559, 0.99440559, 0.97062937, 0.96083916, 0.94405594,\n",
            "       0.92167832, 0.93986014, 0.9006993 , 0.93566434, 0.9034965 ,\n",
            "       0.91608392, 0.86853147, 0.90909091, 0.86153846, 0.90909091,\n",
            "       0.86713287, 0.90629371, 0.85734266, 0.84475524, 0.83776224,\n",
            "       0.84335664, 0.83776224, 0.84195804, 0.83636364, 0.83916084,\n",
            "       0.83216783, 0.83916084, 0.80979021, 0.83916084, 0.83776224,\n",
            "       0.83916084, 0.82237762, 0.83916084, 0.83776224, 0.83916084,\n",
            "       0.82377622, 0.94685315, 0.92307692, 0.93426573, 0.92167832,\n",
            "       0.92167832, 0.86573427, 0.91468531, 0.88391608, 0.91328671,\n",
            "       0.88671329, 0.9034965 , 0.87832168, 0.9020979 , 0.85174825,\n",
            "       0.9020979 , 0.85594406, 0.8993007 , 0.84755245, 0.98321678,\n",
            "       0.96503497, 0.96363636, 0.93986014, 0.94125874, 0.91188811,\n",
            "       0.94405594, 0.87972028, 0.93846154, 0.89230769, 0.91608392,\n",
            "       0.87272727, 0.90909091, 0.85174825, 0.90909091, 0.85594406,\n",
            "       0.90629371, 0.85734266, 0.99440559, 0.99440559, 0.97062937,\n",
            "       0.95384615, 0.94825175, 0.92587413, 0.94825175, 0.91048951,\n",
            "       0.94685315, 0.9034965 , 0.93006993, 0.88531469, 0.9048951 ,\n",
            "       0.85174825, 0.9020979 , 0.85734266, 0.9020979 , 0.85314685,\n",
            "       0.83916084, 0.7986014 , 0.83776224, 0.82937063, 0.83776224,\n",
            "       0.82657343, 0.83636364, 0.81538462, 0.83636364, 0.82377622,\n",
            "       0.83636364, 0.82517483, 0.83216783, 0.81398601, 0.83216783,\n",
            "       0.83776224, 0.83216783, 0.83916084, 0.9020979 , 0.8979021 ,\n",
            "       0.89090909, 0.89370629, 0.89370629, 0.87692308, 0.88251748,\n",
            "       0.89230769, 0.88391608, 0.87972028, 0.88531469, 0.85174825,\n",
            "       0.88811189, 0.86013986, 0.88811189, 0.85874126, 0.89090909,\n",
            "       0.85454545, 0.97202797, 0.95804196, 0.96083916, 0.93286713,\n",
            "       0.94405594, 0.88811189, 0.93986014, 0.8951049 , 0.94125874,\n",
            "       0.8965035 , 0.92867133, 0.88391608, 0.9034965 , 0.85874126,\n",
            "       0.9020979 , 0.86293706, 0.9034965 , 0.85594406, 0.99440559,\n",
            "       0.99440559, 0.96923077, 0.95104895, 0.94685315, 0.91328671,\n",
            "       0.94545455, 0.9020979 , 0.94825175, 0.9020979 , 0.93006993,\n",
            "       0.87972028, 0.9020979 , 0.85874126, 0.9020979 , 0.85454545,\n",
            "       0.9006993 , 0.86013986, 0.83776224, 0.82937063, 0.83776224,\n",
            "       0.83076923, 0.83776224, 0.84195804, 0.83636364, 0.82937063,\n",
            "       0.83636364, 0.82657343, 0.83636364, 0.80979021, 0.83216783,\n",
            "       0.82797203, 0.83216783, 0.80979021, 0.83216783, 0.83216783,\n",
            "       0.8993007 , 0.9006993 , 0.89090909, 0.89230769, 0.89370629,\n",
            "       0.86993007, 0.88251748, 0.8965035 , 0.88531469, 0.88251748,\n",
            "       0.88111888, 0.86993007, 0.88811189, 0.86433566, 0.89090909,\n",
            "       0.85734266, 0.88671329, 0.84895105, 0.97202797, 0.93706294,\n",
            "       0.96223776, 0.91748252, 0.94405594, 0.91188811, 0.93986014,\n",
            "       0.91048951, 0.94265734, 0.8951049 , 0.93006993, 0.88111888,\n",
            "       0.9048951 , 0.86153846, 0.9048951 , 0.86433566, 0.9020979 ,\n",
            "       0.86013986]), 'split6_train_score': array([0.99300699, 0.99300699, 0.96363636, 0.94825175, 0.93006993,\n",
            "       0.90769231, 0.93426573, 0.8979021 , 0.93146853, 0.8951049 ,\n",
            "       0.9020979 , 0.87692308, 0.8979021 , 0.83776224, 0.8979021 ,\n",
            "       0.82517483, 0.8951049 , 0.82797203, 0.84895105, 0.82517483,\n",
            "       0.84895105, 0.82797203, 0.84615385, 0.82937063, 0.84475524,\n",
            "       0.81538462, 0.84475524, 0.81538462, 0.84195804, 0.80979021,\n",
            "       0.84195804, 0.83496503, 0.84195804, 0.8041958 , 0.83916084,\n",
            "       0.82237762, 0.93286713, 0.91328671, 0.92307692, 0.89230769,\n",
            "       0.91048951, 0.87132867, 0.90769231, 0.87972028, 0.90909091,\n",
            "       0.86993007, 0.8965035 , 0.85734266, 0.8965035 , 0.84615385,\n",
            "       0.8965035 , 0.85454545, 0.89370629, 0.84335664, 0.97762238,\n",
            "       0.96363636, 0.95244755, 0.94545455, 0.92307692, 0.90629371,\n",
            "       0.93846154, 0.88811189, 0.93286713, 0.87832168, 0.9034965 ,\n",
            "       0.87692308, 0.8979021 , 0.85174825, 0.8979021 , 0.84895105,\n",
            "       0.8951049 , 0.83216783, 0.99300699, 0.99300699, 0.95944056,\n",
            "       0.94265734, 0.93146853, 0.91888112, 0.93986014, 0.8951049 ,\n",
            "       0.93706294, 0.88391608, 0.91608392, 0.87272727, 0.91048951,\n",
            "       0.83776224, 0.91048951, 0.84755245, 0.9034965 , 0.85174825,\n",
            "       0.84195804, 0.8       , 0.84195804, 0.82517483, 0.83916084,\n",
            "       0.80839161, 0.83776224, 0.81538462, 0.83776224, 0.83076923,\n",
            "       0.83496503, 0.82237762, 0.83496503, 0.81818182, 0.83496503,\n",
            "       0.82097902, 0.83216783, 0.80979021, 0.91188811, 0.9034965 ,\n",
            "       0.9020979 , 0.89370629, 0.89230769, 0.86853147, 0.88951049,\n",
            "       0.87552448, 0.89230769, 0.87272727, 0.88111888, 0.84895105,\n",
            "       0.87972028, 0.85314685, 0.87972028, 0.85734266, 0.87272727,\n",
            "       0.84755245, 0.97762238, 0.97062937, 0.95104895, 0.91888112,\n",
            "       0.93286713, 0.90629371, 0.93426573, 0.8993007 , 0.93286713,\n",
            "       0.88811189, 0.91048951, 0.86433566, 0.91048951, 0.84195804,\n",
            "       0.91048951, 0.85314685, 0.9034965 , 0.84895105, 0.99300699,\n",
            "       0.99300699, 0.95944056, 0.94825175, 0.92867133, 0.90769231,\n",
            "       0.93846154, 0.9006993 , 0.93706294, 0.88811189, 0.91328671,\n",
            "       0.86293706, 0.91048951, 0.85034965, 0.91048951, 0.85594406,\n",
            "       0.9034965 , 0.84895105, 0.84335664, 0.82097902, 0.84195804,\n",
            "       0.80979021, 0.83916084, 0.82657343, 0.83776224, 0.81818182,\n",
            "       0.83776224, 0.7958042 , 0.83496503, 0.82377622, 0.83496503,\n",
            "       0.8041958 , 0.83496503, 0.79020979, 0.83216783, 0.81958042,\n",
            "       0.91328671, 0.88391608, 0.9020979 , 0.88251748, 0.89230769,\n",
            "       0.87692308, 0.88951049, 0.87972028, 0.88951049, 0.87972028,\n",
            "       0.88111888, 0.85734266, 0.87972028, 0.83496503, 0.87972028,\n",
            "       0.85314685, 0.87272727, 0.85174825, 0.97762238, 0.96223776,\n",
            "       0.95244755, 0.92727273, 0.92727273, 0.89370629, 0.93566434,\n",
            "       0.8979021 , 0.93426573, 0.87552448, 0.91328671, 0.86573427,\n",
            "       0.91048951, 0.85594406, 0.91048951, 0.85594406, 0.9034965 ,\n",
            "       0.84615385]), 'split7_train_score': array([0.99440559, 0.99440559, 0.96923077, 0.94965035, 0.93286713,\n",
            "       0.90629371, 0.93006993, 0.8979021 , 0.92867133, 0.88251748,\n",
            "       0.91188811, 0.87132867, 0.9020979 , 0.85594406, 0.9020979 ,\n",
            "       0.85174825, 0.8979021 , 0.85314685, 0.85034965, 0.83216783,\n",
            "       0.84895105, 0.83916084, 0.84755245, 0.81398601, 0.84615385,\n",
            "       0.83076923, 0.84615385, 0.83496503, 0.84475524, 0.81818182,\n",
            "       0.84335664, 0.82797203, 0.84335664, 0.83216783, 0.84335664,\n",
            "       0.81818182, 0.95244755, 0.91468531, 0.93846154, 0.9048951 ,\n",
            "       0.91748252, 0.87972028, 0.91748252, 0.87832168, 0.91468531,\n",
            "       0.89370629, 0.90629371, 0.86713287, 0.8993007 , 0.83916084,\n",
            "       0.8993007 , 0.84755245, 0.8951049 , 0.85034965, 0.98321678,\n",
            "       0.95664336, 0.95804196, 0.93846154, 0.92867133, 0.90909091,\n",
            "       0.92867133, 0.89090909, 0.92867133, 0.88531469, 0.91188811,\n",
            "       0.87412587, 0.9020979 , 0.85314685, 0.9020979 , 0.84895105,\n",
            "       0.8979021 , 0.85594406, 0.99440559, 0.99440559, 0.96363636,\n",
            "       0.94965035, 0.94125874, 0.91188811, 0.93706294, 0.9006993 ,\n",
            "       0.93566434, 0.89090909, 0.91328671, 0.86853147, 0.91328671,\n",
            "       0.84615385, 0.91048951, 0.86153846, 0.9034965 , 0.86013986,\n",
            "       0.83916084, 0.83776224, 0.83776224, 0.84195804, 0.83776224,\n",
            "       0.81538462, 0.83496503, 0.82237762, 0.83496503, 0.81958042,\n",
            "       0.83496503, 0.82657343, 0.83636364, 0.83076923, 0.83636364,\n",
            "       0.82377622, 0.83636364, 0.79020979, 0.92307692, 0.9034965 ,\n",
            "       0.91188811, 0.87412587, 0.9006993 , 0.87972028, 0.8993007 ,\n",
            "       0.88111888, 0.8979021 , 0.88531469, 0.88531469, 0.86013986,\n",
            "       0.9020979 , 0.85874126, 0.9020979 , 0.85174825, 0.89230769,\n",
            "       0.82797203, 0.97902098, 0.94965035, 0.95944056, 0.94265734,\n",
            "       0.93566434, 0.9034965 , 0.93566434, 0.9048951 , 0.93146853,\n",
            "       0.87692308, 0.91328671, 0.87972028, 0.91048951, 0.84755245,\n",
            "       0.91048951, 0.84335664, 0.9006993 , 0.82937063, 0.99440559,\n",
            "       0.99440559, 0.96363636, 0.94545455, 0.93426573, 0.9034965 ,\n",
            "       0.93566434, 0.9048951 , 0.93146853, 0.89370629, 0.91328671,\n",
            "       0.88391608, 0.91328671, 0.86993007, 0.91048951, 0.85734266,\n",
            "       0.9034965 , 0.85594406, 0.83916084, 0.83356643, 0.83776224,\n",
            "       0.82237762, 0.83776224, 0.83916084, 0.83496503, 0.82797203,\n",
            "       0.83496503, 0.81958042, 0.83496503, 0.82797203, 0.83636364,\n",
            "       0.81818182, 0.83636364, 0.83216783, 0.83636364, 0.83356643,\n",
            "       0.92307692, 0.91608392, 0.91188811, 0.90629371, 0.9006993 ,\n",
            "       0.87272727, 0.9006993 , 0.88811189, 0.8965035 , 0.87692308,\n",
            "       0.88531469, 0.86573427, 0.9020979 , 0.84055944, 0.9020979 ,\n",
            "       0.84755245, 0.89230769, 0.85034965, 0.98181818, 0.97202797,\n",
            "       0.96083916, 0.93286713, 0.93566434, 0.90769231, 0.93566434,\n",
            "       0.88951049, 0.93146853, 0.8965035 , 0.91328671, 0.88811189,\n",
            "       0.91328671, 0.86013986, 0.91048951, 0.86573427, 0.9006993 ,\n",
            "       0.85174825]), 'split8_train_score': array([0.99300699, 0.99300699, 0.96083916, 0.94965035, 0.93566434,\n",
            "       0.91748252, 0.93146853, 0.87412587, 0.93006993, 0.8979021 ,\n",
            "       0.91328671, 0.87692308, 0.9006993 , 0.85034965, 0.9006993 ,\n",
            "       0.84755245, 0.8951049 , 0.86293706, 0.83636364, 0.82097902,\n",
            "       0.83636364, 0.82097902, 0.83356643, 0.81958042, 0.83356643,\n",
            "       0.82377622, 0.83356643, 0.81678322, 0.83076923, 0.82937063,\n",
            "       0.83356643, 0.81258741, 0.83356643, 0.82517483, 0.83076923,\n",
            "       0.8013986 , 0.93286713, 0.9006993 , 0.92027972, 0.87832168,\n",
            "       0.90909091, 0.87692308, 0.90769231, 0.88671329, 0.90629371,\n",
            "       0.88111888, 0.8965035 , 0.86853147, 0.88951049, 0.85314685,\n",
            "       0.88951049, 0.85314685, 0.88391608, 0.84615385, 0.97622378,\n",
            "       0.92447552, 0.95244755, 0.93566434, 0.93426573, 0.8965035 ,\n",
            "       0.92867133, 0.88251748, 0.92867133, 0.89090909, 0.91468531,\n",
            "       0.87132867, 0.9006993 , 0.85314685, 0.9006993 , 0.86013986,\n",
            "       0.8965035 , 0.85174825, 0.99300699, 0.99300699, 0.95944056,\n",
            "       0.94405594, 0.93146853, 0.91188811, 0.93426573, 0.9020979 ,\n",
            "       0.93426573, 0.91048951, 0.91468531, 0.88391608, 0.8993007 ,\n",
            "       0.86013986, 0.8993007 , 0.85734266, 0.89370629, 0.86153846,\n",
            "       0.83216783, 0.82937063, 0.83216783, 0.82517483, 0.82937063,\n",
            "       0.81818182, 0.82937063, 0.81958042, 0.82937063, 0.8041958 ,\n",
            "       0.82657343, 0.82377622, 0.82937063, 0.82517483, 0.82937063,\n",
            "       0.82097902, 0.82657343, 0.7972028 , 0.91608392, 0.89370629,\n",
            "       0.90629371, 0.89230769, 0.8951049 , 0.87972028, 0.8965035 ,\n",
            "       0.87692308, 0.8965035 , 0.87552448, 0.88811189, 0.87132867,\n",
            "       0.87972028, 0.85454545, 0.87972028, 0.84755245, 0.87692308,\n",
            "       0.84335664, 0.97482517, 0.93846154, 0.95384615, 0.92027972,\n",
            "       0.92867133, 0.87972028, 0.93286713, 0.8979021 , 0.93286713,\n",
            "       0.9006993 , 0.91608392, 0.87412587, 0.8993007 , 0.85174825,\n",
            "       0.8993007 , 0.85174825, 0.89370629, 0.86013986, 0.99300699,\n",
            "       0.99300699, 0.95664336, 0.94545455, 0.92867133, 0.92167832,\n",
            "       0.93426573, 0.8965035 , 0.93426573, 0.8965035 , 0.91468531,\n",
            "       0.87552448, 0.8993007 , 0.85174825, 0.8993007 , 0.85034965,\n",
            "       0.89370629, 0.85314685, 0.83216783, 0.82377622, 0.83216783,\n",
            "       0.81958042, 0.82937063, 0.81538462, 0.82937063, 0.81538462,\n",
            "       0.82937063, 0.82797203, 0.82657343, 0.82517483, 0.82937063,\n",
            "       0.82097902, 0.82937063, 0.81678322, 0.82657343, 0.81258741,\n",
            "       0.91608392, 0.88111888, 0.9048951 , 0.87692308, 0.8951049 ,\n",
            "       0.89230769, 0.8965035 , 0.88391608, 0.8965035 , 0.88111888,\n",
            "       0.88951049, 0.86853147, 0.87972028, 0.86013986, 0.87972028,\n",
            "       0.82937063, 0.87692308, 0.85034965, 0.97482517, 0.93846154,\n",
            "       0.94965035, 0.90769231, 0.92587413, 0.8979021 , 0.93286713,\n",
            "       0.88391608, 0.93426573, 0.88391608, 0.91468531, 0.86573427,\n",
            "       0.8993007 , 0.85594406, 0.8993007 , 0.86013986, 0.89370629,\n",
            "       0.86573427]), 'split9_train_score': array([0.99440559, 0.99440559, 0.96363636, 0.95244755, 0.93846154,\n",
            "       0.91188811, 0.93986014, 0.8993007 , 0.93706294, 0.9006993 ,\n",
            "       0.91608392, 0.87832168, 0.91328671, 0.84895105, 0.91328671,\n",
            "       0.85034965, 0.90769231, 0.85314685, 0.84475524, 0.8041958 ,\n",
            "       0.84335664, 0.82657343, 0.84195804, 0.83496503, 0.84055944,\n",
            "       0.82517483, 0.84055944, 0.82517483, 0.83916084, 0.82937063,\n",
            "       0.83916084, 0.83776224, 0.83916084, 0.82237762, 0.83916084,\n",
            "       0.83636364, 0.93986014, 0.92727273, 0.92307692, 0.89370629,\n",
            "       0.91188811, 0.9020979 , 0.92027972, 0.8951049 , 0.91748252,\n",
            "       0.87692308, 0.9034965 , 0.86293706, 0.9034965 , 0.83776224,\n",
            "       0.9034965 , 0.85454545, 0.9006993 , 0.85314685, 0.98321678,\n",
            "       0.96643357, 0.95664336, 0.94125874, 0.93706294, 0.9034965 ,\n",
            "       0.93706294, 0.88811189, 0.93426573, 0.89230769, 0.91328671,\n",
            "       0.88811189, 0.91048951, 0.87132867, 0.91048951, 0.85314685,\n",
            "       0.90769231, 0.85314685, 0.99440559, 0.99440559, 0.96923077,\n",
            "       0.95104895, 0.93426573, 0.91608392, 0.94965035, 0.89230769,\n",
            "       0.94545455, 0.8951049 , 0.91608392, 0.87412587, 0.91048951,\n",
            "       0.85594406, 0.91048951, 0.84895105, 0.91048951, 0.85174825,\n",
            "       0.83776224, 0.82517483, 0.83496503, 0.83216783, 0.83496503,\n",
            "       0.81118881, 0.83356643, 0.84475524, 0.83356643, 0.82237762,\n",
            "       0.83356643, 0.82797203, 0.83356643, 0.81258741, 0.83356643,\n",
            "       0.82797203, 0.83356643, 0.81398601, 0.92447552, 0.90629371,\n",
            "       0.91048951, 0.9034965 , 0.8965035 , 0.9034965 , 0.9034965 ,\n",
            "       0.87832168, 0.9006993 , 0.89230769, 0.88671329, 0.86713287,\n",
            "       0.89230769, 0.84895105, 0.89230769, 0.84335664, 0.88951049,\n",
            "       0.83776224, 0.97762238, 0.95384615, 0.95384615, 0.93706294,\n",
            "       0.92727273, 0.9020979 , 0.93566434, 0.8965035 , 0.93286713,\n",
            "       0.89230769, 0.91188811, 0.88531469, 0.90769231, 0.86713287,\n",
            "       0.91048951, 0.85314685, 0.90769231, 0.86013986, 0.99440559,\n",
            "       0.99440559, 0.96783217, 0.95664336, 0.93146853, 0.91468531,\n",
            "       0.94685315, 0.89230769, 0.94685315, 0.8979021 , 0.91888112,\n",
            "       0.89230769, 0.91048951, 0.85874126, 0.91048951, 0.84895105,\n",
            "       0.90769231, 0.84335664, 0.83776224, 0.82517483, 0.83496503,\n",
            "       0.82377622, 0.83496503, 0.81958042, 0.83356643, 0.83216783,\n",
            "       0.83356643, 0.80559441, 0.83356643, 0.82797203, 0.83356643,\n",
            "       0.82097902, 0.83356643, 0.81398601, 0.83356643, 0.81258741,\n",
            "       0.92447552, 0.88531469, 0.91048951, 0.9048951 , 0.8965035 ,\n",
            "       0.88251748, 0.9034965 , 0.87272727, 0.9006993 , 0.88951049,\n",
            "       0.88671329, 0.86293706, 0.89230769, 0.84615385, 0.89230769,\n",
            "       0.86433566, 0.88951049, 0.84335664, 0.97762238, 0.95944056,\n",
            "       0.95524476, 0.95104895, 0.92727273, 0.89370629, 0.93566434,\n",
            "       0.89090909, 0.93426573, 0.8993007 , 0.91188811, 0.86573427,\n",
            "       0.90769231, 0.85734266, 0.91048951, 0.84195804, 0.90769231,\n",
            "       0.85594406]), 'mean_train_score': array([0.99412294, 0.99412294, 0.96515563, 0.94850071, 0.93562869,\n",
            "       0.91309965, 0.93674894, 0.89616736, 0.93394978, 0.89560616,\n",
            "       0.91127911, 0.87755617, 0.90386182, 0.85418581, 0.90372177,\n",
            "       0.85628665, 0.89924331, 0.85586453, 0.84942881, 0.82311649,\n",
            "       0.84830914, 0.82843431, 0.8470502 , 0.82563437, 0.84453076,\n",
            "       0.82717674, 0.84453076, 0.8211606 , 0.8436916 , 0.82605473,\n",
            "       0.84355135, 0.82619674, 0.84355135, 0.82703747, 0.8427118 ,\n",
            "       0.81933733, 0.94514564, 0.91673483, 0.93213199, 0.89868484,\n",
            "       0.91617814, 0.88567433, 0.91743864, 0.88469139, 0.91575914,\n",
            "       0.8828734 , 0.90316468, 0.87209967, 0.89798515, 0.85012634,\n",
            "       0.8978451 , 0.85292335, 0.89322619, 0.8525071 , 0.98082839,\n",
            "       0.95662083, 0.95661946, 0.93758555, 0.93198977, 0.90484339,\n",
            "       0.93562927, 0.89029128, 0.93296997, 0.89239035, 0.9112797 ,\n",
            "       0.87517541, 0.90316233, 0.85978335, 0.90344244, 0.85516464,\n",
            "       0.89854322, 0.8513845 , 0.99412294, 0.99412294, 0.96641613,\n",
            "       0.94990323, 0.93632759, 0.91813716, 0.94304617, 0.9024642 ,\n",
            "       0.94136687, 0.89630605, 0.91897691, 0.87461401, 0.90722043,\n",
            "       0.85446495, 0.90652093, 0.85614288, 0.9019028 , 0.85362304,\n",
            "       0.83991166, 0.82101879, 0.83879219, 0.82647627, 0.83795283,\n",
            "       0.81962097, 0.83627353, 0.82325949, 0.83627353, 0.82115884,\n",
            "       0.83571409, 0.82465672, 0.83487375, 0.82102114, 0.83487375,\n",
            "       0.82451803, 0.83431431, 0.81640438, 0.92191749, 0.90400443,\n",
            "       0.91170242, 0.8960275 , 0.90008599, 0.88189125, 0.900647  ,\n",
            "       0.88161153, 0.90022683, 0.87937122, 0.88987111, 0.86622201,\n",
            "       0.89168949, 0.8547431 , 0.89154943, 0.85110634, 0.88805116,\n",
            "       0.84872951, 0.97817104, 0.95969932, 0.95732013, 0.93227067,\n",
            "       0.93282933, 0.89770602, 0.93660908, 0.89728428, 0.93534975,\n",
            "       0.89126814, 0.91673797, 0.87797399, 0.9059609 , 0.85866389,\n",
            "       0.90610076, 0.85600498, 0.90106305, 0.85572545, 0.99412294,\n",
            "       0.99412294, 0.96571644, 0.94962214, 0.93492938, 0.91141741,\n",
            "       0.9422072 , 0.9024644 , 0.94136706, 0.89392549, 0.91911696,\n",
            "       0.87895281, 0.90694071, 0.8581019 , 0.90666099, 0.85670506,\n",
            "       0.90134317, 0.85600576, 0.83991166, 0.82507532, 0.83879219,\n",
            "       0.82577854, 0.83795283, 0.82521283, 0.83627353, 0.82073554,\n",
            "       0.83627353, 0.81864136, 0.83571409, 0.82507786, 0.83487375,\n",
            "       0.82283951, 0.83487375, 0.82158214, 0.83431431, 0.82479658,\n",
            "       0.92219761, 0.9013461 , 0.91156256, 0.89658694, 0.9000858 ,\n",
            "       0.8807753 , 0.90092692, 0.88511312, 0.8996672 , 0.88021116,\n",
            "       0.88959139, 0.86454017, 0.89168949, 0.85222699, 0.89196921,\n",
            "       0.85544612, 0.88749153, 0.85068539, 0.9790106 , 0.95788016,\n",
            "       0.95759985, 0.92891168, 0.93157039, 0.90176431, 0.93702885,\n",
            "       0.89756733, 0.93562908, 0.89434918, 0.91701769, 0.87685609,\n",
            "       0.90624043, 0.85726137, 0.90638048, 0.85950344, 0.90092319,\n",
            "       0.85600458]), 'std_train_score': array([0.00083721, 0.00083721, 0.00356153, 0.00513347, 0.00596744,\n",
            "       0.00699239, 0.00440087, 0.00829825, 0.0036794 , 0.00708273,\n",
            "       0.00456207, 0.00471685, 0.0042089 , 0.00807636, 0.00433776,\n",
            "       0.01361479, 0.00431237, 0.01081888, 0.00629616, 0.00889943,\n",
            "       0.00630004, 0.00623232, 0.00687781, 0.01147946, 0.00572107,\n",
            "       0.00899957, 0.00572107, 0.01130323, 0.00637555, 0.01310883,\n",
            "       0.0062528 , 0.00770172, 0.0062528 , 0.01028157, 0.00647758,\n",
            "       0.01009713, 0.0081432 , 0.01128272, 0.00722968, 0.01205298,\n",
            "       0.00548937, 0.01220937, 0.0067129 , 0.00880585, 0.00606585,\n",
            "       0.00748058, 0.00541258, 0.00806255, 0.0038715 , 0.00855655,\n",
            "       0.00380049, 0.0054734 , 0.00490548, 0.00618082, 0.00242737,\n",
            "       0.01465841, 0.00358984, 0.00437291, 0.00648175, 0.00816684,\n",
            "       0.00522294, 0.00568471, 0.00320788, 0.00793773, 0.00446318,\n",
            "       0.00657661, 0.00385267, 0.00681294, 0.00375386, 0.0059246 ,\n",
            "       0.00437808, 0.00879178, 0.00083721, 0.00083721, 0.00458875,\n",
            "       0.00398204, 0.00752202, 0.00471479, 0.00514914, 0.00633305,\n",
            "       0.00493267, 0.00844716, 0.00691184, 0.00735102, 0.00443502,\n",
            "       0.00889941, 0.00437546, 0.00538387, 0.00462453, 0.00564102,\n",
            "       0.0050546 , 0.01465317, 0.00533995, 0.01022547, 0.00529414,\n",
            "       0.00880714, 0.00479798, 0.01383514, 0.00479798, 0.00812646,\n",
            "       0.00522508, 0.00333718, 0.00464565, 0.00931024, 0.00464565,\n",
            "       0.00842953, 0.00508543, 0.01563623, 0.01277653, 0.00653958,\n",
            "       0.01162289, 0.00959421, 0.00807024, 0.01158502, 0.00928877,\n",
            "       0.00654972, 0.0087966 , 0.00628618, 0.0080075 , 0.009386  ,\n",
            "       0.00823535, 0.00614678, 0.0082619 , 0.00624343, 0.00822896,\n",
            "       0.01084173, 0.00638763, 0.01320945, 0.00534761, 0.00808358,\n",
            "       0.0074094 , 0.0079109 , 0.00432268, 0.00479539, 0.00585246,\n",
            "       0.00793836, 0.00803322, 0.00843572, 0.00451441, 0.00890733,\n",
            "       0.00479545, 0.00645022, 0.00430319, 0.01129769, 0.00083721,\n",
            "       0.00083721, 0.00446891, 0.00484921, 0.00659389, 0.00582776,\n",
            "       0.00486822, 0.00469451, 0.00593852, 0.00426381, 0.00706035,\n",
            "       0.00847688, 0.00465559, 0.00571922, 0.00433918, 0.00551852,\n",
            "       0.00416806, 0.00612067, 0.0051694 , 0.0077815 , 0.00533995,\n",
            "       0.00861646, 0.00529414, 0.01342651, 0.00479798, 0.00770285,\n",
            "       0.00479798, 0.01237074, 0.00522508, 0.00881282, 0.00464565,\n",
            "       0.01141916, 0.00464565, 0.01472522, 0.00508543, 0.00922002,\n",
            "       0.01303815, 0.01555488, 0.01169532, 0.01425633, 0.00899189,\n",
            "       0.01040062, 0.00928406, 0.00829907, 0.00872842, 0.00777405,\n",
            "       0.00832642, 0.00601728, 0.00823535, 0.01139892, 0.00815621,\n",
            "       0.01054676, 0.00820854, 0.00485695, 0.00625712, 0.01089036,\n",
            "       0.00682398, 0.01100756, 0.00800062, 0.00703158, 0.00418294,\n",
            "       0.00910413, 0.00566088, 0.00795806, 0.00810267, 0.00921405,\n",
            "       0.0049039 , 0.00580782, 0.00463262, 0.00813624, 0.00424415,\n",
            "       0.00706725])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ## RandomizedSearchCV"
      ],
      "metadata": {
        "id": "s5lJmBErsToN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_search = RandomizedSearchCV(estimator = tree, param_distributions = param_grid_DT,\n",
        "                        n_iter= 10, cv = 10, return_train_score=True)"
      ],
      "metadata": {
        "id": "J_hcaAa1sToO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "DXzDgn8ZsToO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_oversampled, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fb0b2f-30cd-42f9-9b86-71becd9109cc",
        "id": "90wZX0fksToO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([397, 397]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_search.fit(x_train_oversampled, y_train_oversampled);\n",
        "print(r_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa54c331-94c5-4762-c4c6-4ce639d9ce13",
        "id": "KxnDLXNGsToO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'splitter': 'random', 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': None, 'criterion': 'log_loss'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb37e424-2fe0-4bf5-ef4d-473f169e3809",
        "id": "Qk_STDnHsToO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8238291139240506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de ajuste de hiperparâmetros para Decision Tree sem \"Cabin\""
      ],
      "metadata": {
        "id": "29Co4_ls3KTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "param_grid_DT = {'criterion': ['gini', 'entropy','log_loss'],\n",
        "              'splitter': ['best','random'],\n",
        "              'max_depth': [None, 5, 10, 15],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 2, 4],\n",
        "              }"
      ],
      "metadata": {
        "id": "VTqTEVw43KTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV"
      ],
      "metadata": {
        "id": "A6V02avw3KTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_search = GridSearchCV(estimator = tree, param_grid = param_grid_DT,\n",
        "                        cv = 10, return_train_score=True)"
      ],
      "metadata": {
        "id": "YD3Tl5mM3KTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled_no_cabin, y_train_oversampled_no_cabin = sm.fit_resample(X_train_no_cabin, y_train_no_cabin)"
      ],
      "metadata": {
        "id": "e8ROV44B3KTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_oversampled_no_cabin, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa0a097-e0f8-4c9b-ca93-c11abcba09b5",
        "id": "RWSk-NFD3KTp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([384, 384]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_search.fit(x_train_oversampled_no_cabin, y_train_oversampled_no_cabin);\n",
        "print(g_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676a174c-562c-4c77-da1d-814e8278cb9c",
        "id": "LksekVKP3KTq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7475b2-245f-44fd-96a4-7afc0b02d4c2",
        "id": "LN7N4STF3KTq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8385509227614489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ## RandomizedSearchCV"
      ],
      "metadata": {
        "id": "PUYSZJsk3KTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_search = RandomizedSearchCV(estimator = tree, param_distributions = param_grid_DT,\n",
        "                        n_iter= 10, cv = 10, return_train_score=True)"
      ],
      "metadata": {
        "id": "UxB9i9lu3KTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_train_oversampled_no_cabin, y_train_oversampled_no_cabin = sm.fit_resample(X_train_no_cabin, y_train_no_cabin)"
      ],
      "metadata": {
        "id": "ymFRa96r3KTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_oversampled_no_cabin, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8811fc19-04d8-44d8-f327-5f71befeab66",
        "id": "R_fdQ5gK3KTr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([384, 384]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_search.fit(x_train_oversampled_no_cabin, y_train_oversampled_no_cabin);\n",
        "print(r_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2410ebf4-052e-4771-ab8c-382926a9d5d8",
        "id": "cmt-B6sa3KTr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'splitter': 'best', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 15, 'criterion': 'gini'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03971050-50da-402d-8d15-ff86bbe1cafe",
        "id": "E9flhNT-3KTr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8359876965140123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validação Cruzada Knn dados de treino"
      ],
      "metadata": {
        "id": "o2BmtKMvsHfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_scores = cross_val_score(knn, X_train_no_cabin, y_train_no_cabin, cv=10, scoring=\"accuracy\")\n",
        "media_scores = array_scores.sum()/10\n",
        "\n",
        "media_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLj1HKTXsKU4",
        "outputId": "b5cb5e46-1a87-4c54-9405-af6d7f9f67fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7913722478238607"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validação Cruzada Knn dados de teste\n"
      ],
      "metadata": {
        "id": "HHr2MI6uv2i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_scores = cross_val_score(knn, X_test_no_cabin, y_test_no_cabin, cv=10, scoring=\"accuracy\")\n",
        "media_scores = array_scores.sum()/10\n",
        "\n",
        "media_scores"
      ],
      "metadata": {
        "id": "Rqmd4ru-v-pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0234cc42-7816-4f0c-aa7e-abc36eb8ece3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7720797720797721"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    }
  ]
}